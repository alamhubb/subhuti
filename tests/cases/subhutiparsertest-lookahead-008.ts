/**
 * SubhutiParser æµ‹è¯• 008ï¼šå‰ç»ï¼ˆLookaheadï¼‰åŠŸèƒ½æµ‹è¯•
 * 
 * æµ‹è¯•ç›®æ ‡ï¼š
 * 1. lookaheadAfter.not - å­—ç¬¦ä¸²å½¢å¼ï¼ˆåé¢ä¸èƒ½æ˜¯ç‰¹å®šå­—ç¬¦ä¸²ï¼‰
 * 2. lookaheadAfter.not - æ­£åˆ™å½¢å¼ï¼ˆåé¢ä¸èƒ½åŒ¹é…æ­£åˆ™ï¼‰
 * 3. æ¢è¡Œç¬¦å¤„ç†
 * 4. ç‰¹æ®Šå­—ç¬¦å¤„ç†
 * 5. å®é™…åº”ç”¨åœºæ™¯ï¼ˆå¦‚å¯é€‰é“¾ ?. vs ä¸‰å…ƒè¿ç®—ç¬¦ ?ï¼‰
 */

import SubhutiLexer from "../../src/SubhutiLexer.ts"
import { createRegToken, createValueRegToken } from "../../src/struct/SubhutiCreateToken.ts"

// ============================================
// æµ‹è¯•åœºæ™¯1ï¼šåŒºåˆ†å¯é€‰é“¾ ?. å’Œä¸‰å…ƒè¿ç®—ç¬¦ ?
// ============================================

console.log('='.repeat(70))
console.log('SubhutiParser æµ‹è¯• 008ï¼šå‰ç»ï¼ˆLookaheadï¼‰åŠŸèƒ½æµ‹è¯•')
console.log('='.repeat(70))

let passed = 0
let failed = 0

console.log('\nã€åœºæ™¯1ã€‘åŒºåˆ†å¯é€‰é“¾ ?. å’Œä¸‰å…ƒè¿ç®—ç¬¦ ?')
console.log('-'.repeat(70))

const testTokens1 = [
  // å¯é€‰é“¾ï¼š? åé¢ä¸èƒ½æ˜¯ .
  createValueRegToken('Question', /\?/, '?', false, { not: '.' }),
  
  // å¯é€‰é“¾æ“ä½œç¬¦ï¼šå¿…é¡»æ˜¯ ?.
  createValueRegToken('OptionalChaining', /\?\./, '?.'),
  
  createRegToken('Identifier', /[a-zA-Z_][a-zA-Z0-9_]*/),
  createValueRegToken('Colon', /:/, ':'),
  createValueRegToken('Number', /[0-9]+/, '0'),
  createValueRegToken('WhiteSpace', /[ \t\r\n]+/, '', true),
]

// æµ‹è¯•1.1ï¼šåŒ¹é…å¯é€‰é“¾ ?.
console.log('\n[æµ‹è¯•1.1] åŒ¹é…å¯é€‰é“¾: "a?.b"')
try {
  const lexer1_1 = new SubhutiLexer(testTokens1)
  const tokens1_1 = lexer1_1.tokenize('a?.b')
  
  console.log('  Tokens:', tokens1_1.map(t => `${t.tokenName}(${t.tokenValue})`).join(' '))
  
  if (tokens1_1.length === 3 && 
      tokens1_1[0].tokenName === 'Identifier' &&
      tokens1_1[1].tokenName === 'OptionalChaining' &&
      tokens1_1[2].tokenName === 'Identifier') {
    console.log('  âœ… æˆåŠŸï¼šæ­£ç¡®è¯†åˆ«ä¸º Identifier + OptionalChaining + Identifier')
    passed++
  } else {
    console.log('  âŒ å¤±è´¥ï¼šTokenè¯†åˆ«é”™è¯¯')
    failed++
  }
} catch (e: any) {
  console.log('  âŒ å¼‚å¸¸:', e.message)
  failed++
}

// æµ‹è¯•1.2ï¼šåŒ¹é…ä¸‰å…ƒè¿ç®—ç¬¦ ?
console.log('\n[æµ‹è¯•1.2] åŒ¹é…ä¸‰å…ƒè¿ç®—ç¬¦: "a ? b : c"')
try {
  const lexer1_2 = new SubhutiLexer(testTokens1)
  const tokens1_2 = lexer1_2.tokenize('a ? b : c')
  
  console.log('  Tokens:', tokens1_2.map(t => `${t.tokenName}(${t.tokenValue})`).join(' '))
  
  if (tokens1_2.length === 5 && 
      tokens1_2[1].tokenName === 'Question' &&
      tokens1_2[3].tokenName === 'Colon') {
    console.log('  âœ… æˆåŠŸï¼šæ­£ç¡®è¯†åˆ«ä¸ºä¸‰å…ƒè¿ç®—ç¬¦')
    console.log('  éªŒè¯ï¼šQuestion token åé¢ä¸æ˜¯ "."ï¼Œå‰ç»ç”Ÿæ•ˆ')
    passed++
  } else {
    console.log('  âŒ å¤±è´¥ï¼šTokenè¯†åˆ«é”™è¯¯')
    failed++
  }
} catch (e: any) {
  console.log('  âŒ å¼‚å¸¸:', e.message)
  failed++
}

// ============================================
// æµ‹è¯•åœºæ™¯2ï¼šæ¢è¡Œç¬¦å‰ç»ï¼ˆæ­£åˆ™å½¢å¼ï¼‰
// ============================================

console.log('\n\nã€åœºæ™¯2ã€‘æ¢è¡Œç¬¦å‰ç»ï¼ˆæ­£åˆ™å½¢å¼ï¼‰')
console.log('-'.repeat(70))

const testTokens2 = [
  // åˆ†å·ï¼šåé¢ä¸èƒ½ç´§è·Ÿæ¢è¡Œç¬¦ï¼ˆæµ‹è¯•ç”¨ä¾‹ï¼‰
  // âš ï¸ ä½¿ç”¨ ^ é”šç‚¹åŒ¹é…å­—ç¬¦ä¸²å¼€å¤´
  createValueRegToken('SemicolonNoNewline', /;/, ';', false, { not: /^[\r\n]/ }),
  
  // æ™®é€šåˆ†å·ï¼ˆä¼šè¢«ä¸Šé¢çš„è§„åˆ™ä¼˜å…ˆåŒ¹é…ï¼‰
  createValueRegToken('Semicolon', /;/, ';'),
  
  createRegToken('Identifier', /[a-zA-Z_][a-zA-Z0-9_]*/),
  createValueRegToken('WhiteSpace', /[ \t]+/, '', true),  // ä¸åŒ…å«æ¢è¡Œç¬¦
  createValueRegToken('LineBreak', /[\r\n]+/, '\n', true),  // å•ç‹¬å¤„ç†æ¢è¡Œç¬¦
]

// æµ‹è¯•2.1ï¼šåˆ†å·åé¢æ˜¯ç©ºæ ¼ï¼ˆéæ¢è¡Œç¬¦ï¼‰
console.log('\n[æµ‹è¯•2.1] åˆ†å·åé¢æ˜¯ç©ºæ ¼: "a; b"')
try {
  const lexer2_1 = new SubhutiLexer(testTokens2)
  const tokens2_1 = lexer2_1.tokenize('a; b')
  
  console.log('  Tokens:', tokens2_1.map(t => `${t.tokenName}(${t.tokenValue})`).join(' '))
  
  if (tokens2_1.length === 3 && tokens2_1[1].tokenName === 'SemicolonNoNewline') {
    console.log('  âœ… æˆåŠŸï¼šåˆ†å·åé¢ä¸æ˜¯æ¢è¡Œç¬¦ï¼ŒåŒ¹é… SemicolonNoNewline')
    passed++
  } else {
    console.log('  âŒ å¤±è´¥ï¼šåº”è¯¥åŒ¹é… SemicolonNoNewline')
    failed++
  }
} catch (e: any) {
  console.log('  âŒ å¼‚å¸¸:', e.message)
  failed++
}

// æµ‹è¯•2.2ï¼šåˆ†å·åé¢æ˜¯æ¢è¡Œç¬¦
console.log('\n[æµ‹è¯•2.2] åˆ†å·åé¢æ˜¯æ¢è¡Œç¬¦: "a;\\nb"')
try {
  const lexer2_2 = new SubhutiLexer(testTokens2)
  const tokens2_2 = lexer2_2.tokenize('a;\nb')
  
  console.log('  Tokens:', tokens2_2.map(t => `${t.tokenName}(${t.tokenValue})`).join(' '))
  
  if (tokens2_2.length === 3 && tokens2_2[1].tokenName === 'Semicolon') {
    console.log('  âœ… æˆåŠŸï¼šåˆ†å·åé¢æ˜¯æ¢è¡Œç¬¦ï¼Œè·³è¿‡ SemicolonNoNewlineï¼ŒåŒ¹é…æ™®é€š Semicolon')
    console.log('  éªŒè¯ï¼šæ­£åˆ™å‰ç»ç”Ÿæ•ˆï¼ˆnot: /[\\r\\n]/ï¼‰')
    passed++
  } else {
    console.log('  âŒ å¤±è´¥ï¼šåº”è¯¥åŒ¹é…æ™®é€š Semicolonï¼Œå®é™…:', tokens2_2[1]?.tokenName)
    failed++
  }
} catch (e: any) {
  console.log('  âŒ å¼‚å¸¸:', e.message)
  failed++
}

// ============================================
// æµ‹è¯•åœºæ™¯3ï¼šæ•°å­—åç¼€å‰ç»
// ============================================

console.log('\n\nã€åœºæ™¯3ã€‘æ•°å­—åç¼€å‰ç»')
console.log('-'.repeat(70))

const testTokens3 = [
  // æ•´æ•°ï¼šåé¢ä¸èƒ½æ˜¯å°æ•°ç‚¹æˆ–å­—æ¯ï¼ˆé¿å…åŒ¹é…åˆ° 123.45 æˆ– 123nï¼‰
  // âš ï¸ ä½¿ç”¨ ^ é”šç‚¹åŒ¹é…å­—ç¬¦ä¸²å¼€å¤´
  createValueRegToken('Integer', /[0-9]+/, '0', false, { not: /^[.a-zA-Z]/ }),
  
  // æµ®ç‚¹æ•°
  createValueRegToken('Float', /[0-9]+\.[0-9]+/, '0.0'),
  
  // BigIntï¼ˆæ•°å­— + nï¼‰
  createValueRegToken('BigInt', /[0-9]+n/, '0n'),
  
  createRegToken('Identifier', /[a-zA-Z_][a-zA-Z0-9_]*/),
  createValueRegToken('WhiteSpace', /[ \t\r\n]+/, '', true),
]

// æµ‹è¯•3.1ï¼šçº¯æ•´æ•°
console.log('\n[æµ‹è¯•3.1] çº¯æ•´æ•°: "123"')
try {
  const lexer3_1 = new SubhutiLexer(testTokens3)
  const tokens3_1 = lexer3_1.tokenize('123')
  
  console.log('  Tokens:', tokens3_1.map(t => `${t.tokenName}(${t.tokenValue})`).join(' '))
  
  if (tokens3_1.length === 1 && tokens3_1[0].tokenName === 'Integer') {
    console.log('  âœ… æˆåŠŸï¼šè¯†åˆ«ä¸º Integer')
    passed++
  } else {
    console.log('  âŒ å¤±è´¥')
    failed++
  }
} catch (e: any) {
  console.log('  âŒ å¼‚å¸¸:', e.message)
  failed++
}

// æµ‹è¯•3.2ï¼šæµ®ç‚¹æ•°ï¼ˆå‰ç»é˜»æ­¢IntegeråŒ¹é…ï¼‰
console.log('\n[æµ‹è¯•3.2] æµ®ç‚¹æ•°: "123.45"')
try {
  const lexer3_2 = new SubhutiLexer(testTokens3)
  const tokens3_2 = lexer3_2.tokenize('123.45')
  
  console.log('  Tokens:', tokens3_2.map(t => `${t.tokenName}(${t.tokenValue})`).join(' '))
  
  if (tokens3_2.length === 1 && tokens3_2[0].tokenName === 'Float') {
    console.log('  âœ… æˆåŠŸï¼šInteger è¢«å‰ç»é˜»æ­¢ï¼Œæ­£ç¡®åŒ¹é… Float')
    console.log('  éªŒè¯ï¼šInteger çš„ not: /[.a-zA-Z]/ ç”Ÿæ•ˆ')
    passed++
  } else {
    console.log('  âŒ å¤±è´¥ï¼šåº”è¯¥åŒ¹é… Floatï¼Œå®é™…:', tokens3_2[0]?.tokenName)
    failed++
  }
} catch (e: any) {
  console.log('  âŒ å¼‚å¸¸:', e.message)
  failed++
}

// æµ‹è¯•3.3ï¼šBigIntï¼ˆå‰ç»é˜»æ­¢IntegeråŒ¹é…ï¼‰
console.log('\n[æµ‹è¯•3.3] BigInt: "123n"')
try {
  const lexer3_3 = new SubhutiLexer(testTokens3)
  const tokens3_3 = lexer3_3.tokenize('123n')
  
  console.log('  Tokens:', tokens3_3.map(t => `${t.tokenName}(${t.tokenValue})`).join(' '))
  
  if (tokens3_3.length === 1 && tokens3_3[0].tokenName === 'BigInt') {
    console.log('  âœ… æˆåŠŸï¼šInteger è¢«å‰ç»é˜»æ­¢ï¼Œæ­£ç¡®åŒ¹é… BigInt')
    passed++
  } else {
    console.log('  âŒ å¤±è´¥ï¼šåº”è¯¥åŒ¹é… BigIntï¼Œå®é™…:', tokens3_3[0]?.tokenName)
    failed++
  }
} catch (e: any) {
  console.log('  âŒ å¼‚å¸¸:', e.message)
  failed++
}

// ============================================
// æµ‹è¯•åœºæ™¯4ï¼šå…³é”®å­—è¾¹ç•Œå‰ç»
// ============================================

console.log('\n\nã€åœºæ™¯4ã€‘å…³é”®å­—è¾¹ç•Œå‰ç»')
console.log('-'.repeat(70))

const testTokens4 = [
  // âš ï¸ é‡è¦ï¼šå…³é”®å­—å¿…é¡»æ”¾åœ¨ Identifier ä¹‹å‰ï¼
  // âš ï¸ å‰ç»æ­£åˆ™å¿…é¡»ä½¿ç”¨ ^ é”šç‚¹ï¼Œå¦åˆ™ä¼šåŒ¹é…å­—ç¬¦ä¸²ä¸­ä»»æ„ä½ç½®
  // å…³é”®å­— "in"ï¼šåé¢ä¸èƒ½æ˜¯å­—æ¯æˆ–æ•°å­—ï¼ˆé¿å…åŒ¹é…åˆ° indexã€int ç­‰ï¼‰
  createValueRegToken('InKeyword', /in/, 'in', false, { not: /^[a-zA-Z0-9_]/ }),
  
  // å…³é”®å­— "if"
  createValueRegToken('IfKeyword', /if/, 'if', false, { not: /^[a-zA-Z0-9_]/ }),
  
  // Identifier æ”¾åœ¨å…³é”®å­—ä¹‹å
  createRegToken('Identifier', /[a-zA-Z_][a-zA-Z0-9_]*/),
  createValueRegToken('WhiteSpace', /[ \t\r\n]+/, '', true),
]

// æµ‹è¯•4.1ï¼šå…³é”®å­— inï¼ˆç‹¬ç«‹ï¼‰
console.log('\n[æµ‹è¯•4.1] å…³é”®å­— in: "x in array"')
try {
  const lexer4_1 = new SubhutiLexer(testTokens4)
  const tokens4_1 = lexer4_1.tokenize('x in array')
  
  console.log('  Tokens:', tokens4_1.map(t => `${t.tokenName}(${t.tokenValue})`).join(' '))
  
  if (tokens4_1.length === 3 && tokens4_1[1].tokenName === 'InKeyword') {
    console.log('  âœ… æˆåŠŸï¼šè¯†åˆ«ä¸ºå…³é”®å­— InKeyword')
    passed++
  } else {
    console.log('  âŒ å¤±è´¥')
    failed++
  }
} catch (e: any) {
  console.log('  âŒ å¼‚å¸¸:', e.message)
  failed++
}

// æµ‹è¯•4.2ï¼šæ ‡è¯†ç¬¦ indexï¼ˆå‰ç»é˜»æ­¢InKeywordï¼‰
console.log('\n[æµ‹è¯•4.2] æ ‡è¯†ç¬¦ index: "index"')
try {
  const lexer4_2 = new SubhutiLexer(testTokens4)
  const tokens4_2 = lexer4_2.tokenize('index')
  
  console.log('  Tokens:', tokens4_2.map(t => `${t.tokenName}(${t.tokenValue})`).join(' '))
  
  if (tokens4_2.length === 1 && tokens4_2[0].tokenName === 'Identifier') {
    console.log('  âœ… æˆåŠŸï¼šInKeyword è¢«å‰ç»é˜»æ­¢ï¼Œè¯†åˆ«ä¸ºå®Œæ•´çš„ Identifier')
    console.log('  éªŒè¯ï¼šInKeyword çš„ not: /[a-zA-Z0-9_]/ ç”Ÿæ•ˆ')
    passed++
  } else {
    console.log('  âŒ å¤±è´¥ï¼šåº”è¯¥åŒ¹é… Identifierï¼Œå®é™…:', tokens4_2[0]?.tokenName)
    failed++
  }
} catch (e: any) {
  console.log('  âŒ å¼‚å¸¸:', e.message)
  failed++
}

// æµ‹è¯•4.3ï¼šæ ‡è¯†ç¬¦ iffy
console.log('\n[æµ‹è¯•4.3] æ ‡è¯†ç¬¦ iffy: "iffy"')
try {
  const lexer4_3 = new SubhutiLexer(testTokens4)
  const tokens4_3 = lexer4_3.tokenize('iffy')
  
  console.log('  Tokens:', tokens4_3.map(t => `${t.tokenName}(${t.tokenValue})`).join(' '))
  
  if (tokens4_3.length === 1 && tokens4_3[0].tokenName === 'Identifier') {
    console.log('  âœ… æˆåŠŸï¼šIfKeyword è¢«å‰ç»é˜»æ­¢ï¼Œè¯†åˆ«ä¸ºå®Œæ•´çš„ Identifier')
    passed++
  } else {
    console.log('  âŒ å¤±è´¥')
    failed++
  }
} catch (e: any) {
  console.log('  âŒ å¼‚å¸¸:', e.message)
  failed++
}

// ============================================
// æµ‹è¯•åœºæ™¯5ï¼šç‰¹æ®Šå­—ç¬¦å‰ç»
// ============================================

console.log('\n\nã€åœºæ™¯5ã€‘ç‰¹æ®Šå­—ç¬¦å‰ç»')
console.log('-'.repeat(70))

const testTokens5 = [
  // å‡å·ï¼šåé¢ä¸æ˜¯ > ï¼ˆé¿å…åŒ¹é…ç®­å¤´å‡½æ•° ->ï¼‰
  createValueRegToken('Minus', /-/, '-', false, { not: '>' }),
  
  // ç®­å¤´å‡½æ•°
  createValueRegToken('Arrow', /->/, '->'),
  
  // åŠ å·ï¼šåé¢ä¸æ˜¯ + ï¼ˆé¿å…åŒ¹é… ++ï¼‰
  createValueRegToken('Plus', /\+/, '+', false, { not: '+' }),
  
  // è‡ªå¢
  createValueRegToken('PlusPlus', /\+\+/, '++'),
  
  createRegToken('Identifier', /[a-zA-Z_][a-zA-Z0-9_]*/),
  createValueRegToken('WhiteSpace', /[ \t\r\n]+/, '', true),
]

// æµ‹è¯•5.1ï¼šç®­å¤´å‡½æ•° ->
console.log('\n[æµ‹è¯•5.1] ç®­å¤´å‡½æ•°: "a -> b"')
try {
  const lexer5_1 = new SubhutiLexer(testTokens5)
  const tokens5_1 = lexer5_1.tokenize('a -> b')
  
  console.log('  Tokens:', tokens5_1.map(t => `${t.tokenName}(${t.tokenValue})`).join(' '))
  
  if (tokens5_1.length === 3 && tokens5_1[1].tokenName === 'Arrow') {
    console.log('  âœ… æˆåŠŸï¼šMinus è¢«å‰ç»é˜»æ­¢ï¼Œæ­£ç¡®åŒ¹é… Arrow')
    passed++
  } else {
    console.log('  âŒ å¤±è´¥')
    failed++
  }
} catch (e: any) {
  console.log('  âŒ å¼‚å¸¸:', e.message)
  failed++
}

// æµ‹è¯•5.2ï¼šå‡æ³•è¿ç®— -
console.log('\n[æµ‹è¯•5.2] å‡æ³•è¿ç®—: "a - b"')
try {
  const lexer5_2 = new SubhutiLexer(testTokens5)
  const tokens5_2 = lexer5_2.tokenize('a - b')
  
  console.log('  Tokens:', tokens5_2.map(t => `${t.tokenName}(${t.tokenValue})`).join(' '))
  
  if (tokens5_2.length === 3 && tokens5_2[1].tokenName === 'Minus') {
    console.log('  âœ… æˆåŠŸï¼šè¯†åˆ«ä¸º Minusï¼ˆåé¢ä¸æ˜¯ >ï¼‰')
    passed++
  } else {
    console.log('  âŒ å¤±è´¥')
    failed++
  }
} catch (e: any) {
  console.log('  âŒ å¼‚å¸¸:', e.message)
  failed++
}

// æµ‹è¯•5.3ï¼šè‡ªå¢è¿ç®— ++
console.log('\n[æµ‹è¯•5.3] è‡ªå¢è¿ç®—: "a++"')
try {
  const lexer5_3 = new SubhutiLexer(testTokens5)
  const tokens5_3 = lexer5_3.tokenize('a++')
  
  console.log('  Tokens:', tokens5_3.map(t => `${t.tokenName}(${t.tokenValue})`).join(' '))
  
  if (tokens5_3.length === 2 && tokens5_3[1].tokenName === 'PlusPlus') {
    console.log('  âœ… æˆåŠŸï¼šPlus è¢«å‰ç»é˜»æ­¢ï¼Œæ­£ç¡®åŒ¹é… PlusPlus')
    passed++
  } else {
    console.log('  âŒ å¤±è´¥')
    failed++
  }
} catch (e: any) {
  console.log('  âŒ å¼‚å¸¸:', e.message)
  failed++
}

// æµ‹è¯•5.4ï¼šåŠ æ³•è¿ç®— +
console.log('\n[æµ‹è¯•5.4] åŠ æ³•è¿ç®—: "a + b"')
try {
  const lexer5_4 = new SubhutiLexer(testTokens5)
  const tokens5_4 = lexer5_4.tokenize('a + b')
  
  console.log('  Tokens:', tokens5_4.map(t => `${t.tokenName}(${t.tokenValue})`).join(' '))
  
  if (tokens5_4.length === 3 && tokens5_4[1].tokenName === 'Plus') {
    console.log('  âœ… æˆåŠŸï¼šè¯†åˆ«ä¸º Plusï¼ˆåé¢ä¸æ˜¯ +ï¼‰')
    passed++
  } else {
    console.log('  âŒ å¤±è´¥')
    failed++
  }
} catch (e: any) {
  console.log('  âŒ å¼‚å¸¸:', e.message)
  failed++
}

// ============================================
// æµ‹è¯•æ€»ç»“
// ============================================

console.log('\n' + '='.repeat(70))
console.log('æµ‹è¯•æ€»ç»“')
console.log('='.repeat(70))
console.log(`é€šè¿‡: ${passed}/${passed + failed}`)
console.log(`å¤±è´¥: ${failed}/${passed + failed}`)
console.log('='.repeat(70))

console.log('\nğŸ“‹ å‰ç»ï¼ˆLookaheadï¼‰åŠŸèƒ½è¦ç‚¹ï¼š')
console.log('1. lookaheadAfter.not æ”¯æŒå­—ç¬¦ä¸²å’Œæ­£åˆ™è¡¨è¾¾å¼')
console.log('2. ç”¨äºåŒºåˆ†æ˜“æ··æ·†çš„ tokenï¼ˆå¦‚ ?. vs ?ï¼Œ-> vs -ï¼‰')
console.log('3. å¯å¤„ç†æ¢è¡Œç¬¦ã€å­—æ¯ã€æ•°å­—ç­‰å„ç§å­—ç¬¦')
console.log('4. ä¸»è¦ç”¨äºè¯æ³•åˆ†æå±‚é¢çš„æ­§ä¹‰æ¶ˆé™¤')
console.log('5. å®é™…åº”ç”¨ï¼šå¯é€‰é“¾ã€å…³é”®å­—è¾¹ç•Œã€æ•°å­—åç¼€ç­‰')

console.log('\nâš ï¸  å½“å‰å®ç°çŠ¶æ€ï¼š')
console.log('âœ… å·²å®ç°ï¼šlookaheadAfter.notï¼ˆå­—ç¬¦ä¸²å’Œæ­£åˆ™ï¼‰')
console.log('âŒ æœªå®ç°ï¼šlookaheadAfter.is')
console.log('âŒ æœªå®ç°ï¼šlookaheadAfter.in')
console.log('âŒ æœªå®ç°ï¼šlookaheadAfter.notIn')

if (failed === 0) {
  console.log('\nâœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼')
  process.exit(0)
} else {
  console.log('\nâŒ æœ‰æµ‹è¯•å¤±è´¥')
  process.exit(1)
}

