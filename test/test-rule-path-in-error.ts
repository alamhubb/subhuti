/**
 * æµ‹è¯•é”™è¯¯ä¿¡æ¯ä¸­çš„è§„åˆ™è·¯å¾„æ˜¾ç¤º
 */

import SubhutiLexer from "../src/SubhutiLexer.ts"
import SubhutiParser, { Subhuti, SubhutiRule } from "../src/SubhutiParser.ts"
import SubhutiTokenConsumer from "../src/SubhutiTokenConsumer.ts"
import { createKeywordToken, createRegToken } from "../src/struct/SubhutiCreateToken"
import type { SubhutiTokenConsumerConstructor } from "../src/SubhutiParser.ts"
import SubhutiMatchToken from "../src/struct/SubhutiMatchToken"
import { ParsingError } from "../src/SubhutiError.ts"

// ============================================
// å®šä¹‰Tokené›†
// ============================================

const testTokens = [
    createKeywordToken('LetTok', 'let'),
    createRegToken('Identifier', /[a-zA-Z_][a-zA-Z0-9_]*/),
    createKeywordToken('Assign', '='),
    createRegToken('Number', /[0-9]+/),
    createKeywordToken('Semicolon', ';'),
    createRegToken('Whitespace', /\s+/, true),  // è·³è¿‡ç©ºæ ¼
]

// åˆ›å»º token å¯¹è±¡ï¼ˆç”¨äº consumeï¼‰
const testTokensObj = {
    LetTok: testTokens[0],
    Identifier: testTokens[1],
    Assign: testTokens[2],
    Number: testTokens[3],
    Semicolon: testTokens[4],
}

class TestTokenConsumer extends SubhutiTokenConsumer {
    LetTok() { return this.consume(testTokensObj.LetTok) }
    Identifier() { return this.consume(testTokensObj.Identifier) }
    Assign() { return this.consume(testTokensObj.Assign) }
    Number() { return this.consume(testTokensObj.Number) }
    Semicolon() { return this.consume(testTokensObj.Semicolon) }
}

// ============================================
// æµ‹è¯•ï¼šè§¦å‘"æˆåŠŸä½†ä¸æ¶ˆè´¹ token"é”™è¯¯
// ============================================

@Subhuti
class BadParser extends SubhutiParser<TestTokenConsumer> {
    constructor(tokens: SubhutiMatchToken[]) {
        super(tokens)
    }

    getTokenConsumerConstructor(): SubhutiTokenConsumerConstructor<TestTokenConsumer> {
        return TestTokenConsumer
    }

    @SubhutiRule
    Program() {
        this.Statement()
        return this.curCst
    }

    @SubhutiRule
    Statement() {
        // âŒ é”™è¯¯ï¼šæˆåŠŸä½†ä¸æ¶ˆè´¹ä»»ä½• token
        return this.curCst
    }
}

console.log('ğŸ§ª æµ‹è¯•é”™è¯¯ä¿¡æ¯ä¸­çš„è§„åˆ™è·¯å¾„æ˜¾ç¤º\n')
console.log('='.repeat(80))

try {
    const lexer = new SubhutiLexer(testTokens)
    const tokens = lexer.tokenize('let x = 1')
    const parser = new BadParser(tokens)
    parser.Program()
    
    console.log('\nâŒ å¤±è´¥ï¼šåº”è¯¥æŠ›å‡ºé”™è¯¯')
} catch (e: any) {
    if (e instanceof ParsingError && e.type === 'infinite-loop') {
        console.log('\nâœ… æˆåŠŸï¼šæ£€æµ‹åˆ°æ— é™å¾ªç¯é”™è¯¯\n')
        console.log('é”™è¯¯ä¿¡æ¯:')
        console.log('='.repeat(80))
        console.log(e.message)
        console.log('='.repeat(80))
        
        // æ£€æŸ¥æ˜¯å¦åŒ…å«è§„åˆ™è·¯å¾„
        if (e.rulePath) {
            console.log('\nâœ… è§„åˆ™è·¯å¾„å·²åŒ…å«åœ¨é”™è¯¯ä¸­')
            console.log('\nè§„åˆ™è·¯å¾„å†…å®¹:')
            console.log(e.rulePath)
        } else {
            console.log('\nâš ï¸  è§„åˆ™è·¯å¾„æœªåŒ…å«ï¼ˆå¯èƒ½æ²¡æœ‰å¼€å¯è°ƒè¯•æ¨¡å¼ï¼‰')
        }
        
        // æ£€æŸ¥ hint
        if (e.hint) {
            console.log('\nâœ… Hint å·²åŒ…å«')
            console.log(`Hint: ${e.hint}`)
        }
    } else {
        console.log('\nâŒ å¤±è´¥ï¼šé”™è¯¯ç±»å‹ä¸æ­£ç¡®')
        console.log('å®é™…é”™è¯¯:', e.message)
    }
}

console.log('\n' + '='.repeat(80))
console.log('âœ… æµ‹è¯•å®Œæˆï¼')

