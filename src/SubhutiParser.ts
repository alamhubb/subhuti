/**
 * Subhuti Parser - é«˜æ€§èƒ½ PEG Parser æ¡†æ¶
 *
 * æ ¸å¿ƒç‰¹æ€§ï¼š
 * - Packrat Parsingï¼ˆçº¿æ€§æ—¶é—´å¤æ‚åº¦ï¼ŒLRU ç¼“å­˜ï¼‰
 * - è¿”å›å€¼è¯­ä¹‰ï¼ˆæˆåŠŸè¿”å› CSTï¼Œå¤±è´¥è¿”å› undefinedï¼‰
 *
 * æ¶æ„è®¾è®¡ï¼š
 * - ç»§æ‰¿ SubhutiTokenLookaheadï¼ˆå‰ç»èƒ½åŠ›ï¼‰
 * - å®ç° ITokenConsumerContextï¼ˆæä¾›æ¶ˆè´¹æ¥å£ï¼‰
 * - æ”¯æŒæ³›å‹æ‰©å±• SubhutiTokenConsumer
 *
 * @version 5.0.0
 */

import SubhutiTokenLookahead from "./SubhutiTokenLookahead.ts"
import SubhutiCst from "./struct/SubhutiCst.ts";
import type SubhutiMatchToken from "./struct/SubhutiMatchToken.ts";
import {SubhutiErrorHandler, ParsingError} from "./SubhutiError.ts";
import {SubhutiTraceDebugger} from "./SubhutiDebug.ts";
import {SubhutiPackratCache, type SubhutiPackratCacheResult} from "./SubhutiPackratCache.ts";
import SubhutiTokenConsumer from "./SubhutiTokenConsumer.ts";
import {SubhutiDebugRuleTracePrint, setShowRulePath} from "./SubhutiDebugRuleTracePrint.ts";
import SubhutiLexer, {LexicalGoal, TokenCacheEntry} from "./SubhutiLexer.ts";
import {SubhutiCreateToken} from "./struct/SubhutiCreateToken.ts";

// Grammar Validation
import {SubhutiGrammarValidator} from "./validation/SubhutiGrammarValidator.ts";

// ============================================
// ç±»å‹å®šä¹‰
// ============================================

export type RuleFunction = () => SubhutiCst | undefined

export interface SubhutiParserOr {
    alt: RuleFunction
}

export interface SubhutiBackData {
    /** æºç ä½ç½® */
    codeIndex: number
    /** è¡Œå· */
    codeLine: number
    /** åˆ—å· */
    codeColumn: number
    /** ä¸Šä¸€ä¸ª token åç§° */
    lastTokenName: string | null
    /** CST children é•¿åº¦ */
    curCstChildrenLength: number
    /** å·²è§£æ token æ•°é‡ï¼ˆç”¨äºæ¢å¤ parsedTokensï¼‰ */
    parsedTokensLength: number
}

/**
 * éƒ¨åˆ†åŒ¹é…è®°å½•ï¼ˆç”¨äºå®¹é”™æ¨¡å¼ï¼‰
 * åœ¨å›æº¯æ—¶è®°å½•å·²æ¶ˆè´¹ token çš„ CST ç»“æ„
 */
export interface PartialMatchRecord {
    children: SubhutiCst[]    // éƒ¨åˆ†åŒ¹é…çš„ childrenï¼ˆå¼•ç”¨ï¼‰
    parentCst: SubhutiCst     // çˆ¶èŠ‚ç‚¹ï¼ˆæ¢å¤æ—¶æŠŠ children æ”¾åˆ°è¿™é‡Œï¼‰
    endTokenIndex: number     // æ¶ˆè€—åˆ°çš„ token ç´¢å¼•
    startTokenIndex: number   // èµ·å§‹ token ç´¢å¼•
}

/**
 * è§£æè®°å½•æ ‘èŠ‚ç‚¹ï¼ˆç”¨äºå®¹é”™æ¨¡å¼ï¼‰
 * åªå¢ä¸åˆ ï¼Œè®°å½•æ‰€æœ‰è§£æå°è¯•è·¯å¾„
 */
export interface ParseRecordNode {
    name: string                  // è§„åˆ™åæˆ– token å
    children: ParseRecordNode[]   // å­èŠ‚ç‚¹ï¼ˆåªå¢ä¸åˆ ï¼‰
    startTokenIndex: number       // è¯¥èŠ‚ç‚¹å¼€å§‹çš„ token ç´¢å¼•
    endTokenIndex: number         // è¯¥èŠ‚ç‚¹æ¶ˆè€—åˆ°çš„ token ç´¢å¼•
    token?: SubhutiMatchToken     // å¦‚æœæ˜¯ token å¶å­èŠ‚ç‚¹
    value?: string                // token å€¼
}

// ============================================
// è£…é¥°å™¨ç³»ç»Ÿ
// ============================================

export function Subhuti<E extends SubhutiTokenLookahead, T extends new (...args: any[]) => SubhutiParser<E>>(
    target: T,
    context: ClassDecoratorContext
) {
    // ä¸ä½¿ç”¨ context.metadataï¼Œå› ä¸º tsdown/rolldown ç¼–è¯‘åä¸æ”¯æŒ
    return target
}

export function SubhutiRule(targetFun: any, context: ClassMethodDecoratorContext) {
    const ruleName = targetFun.name
    // åœ¨è¿è¡Œæ—¶é€šè¿‡ this.constructor.name è·å–ç±»å
    const wrappedFunction = function (...args: any[]): SubhutiCst | undefined {
        const className = this.constructor.name
        return this.executeRuleWrapper(targetFun, ruleName, className, ...args)
    }

    Object.defineProperty(wrappedFunction, 'name', {value: ruleName})

    // âœ… ä¿å­˜åŸå§‹å‡½æ•°å¼•ç”¨ï¼ˆä¾› SubhutiRuleCollector ä½¿ç”¨ï¼‰
    Object.defineProperty(wrappedFunction, '__originalFunction__', {
        value: targetFun,
        writable: false,
        enumerable: false,
        configurable: false
    })

    // âœ… æ·»åŠ å…ƒæ•°æ®æ ‡è®°ï¼Œæ ‡è¯†è¿™æ˜¯ä¸€ä¸ªè§„åˆ™æ–¹æ³•
    Object.defineProperty(wrappedFunction, '__isSubhutiRule__', {
        value: true,
        writable: false,
        enumerable: false,
        configurable: false
    })

    return wrappedFunction
}

export type SubhutiTokenConsumerConstructor<T extends SubhutiTokenConsumer> =
    new (parser: SubhutiParser) => T

/**
 * Parser æ„é€ é€‰é¡¹
 */
export interface SubhutiParserOptions<T extends SubhutiTokenConsumer = SubhutiTokenConsumer> {
    /** TokenConsumer ç±»ï¼ˆå¯é€‰ï¼‰ */
    tokenConsumer?: SubhutiTokenConsumerConstructor<T>
    /** Token å®šä¹‰ï¼ˆç”¨äºæŒ‰éœ€è¯æ³•åˆ†ææ¨¡å¼ï¼‰ */
    tokenDefinitions?: SubhutiCreateToken[]
}

// ============================================
// SubhutiParser æ ¸å¿ƒç±»
// ============================================

export default class SubhutiParser<T extends SubhutiTokenConsumer = SubhutiTokenConsumer>
    extends SubhutiTokenLookahead {
    // æ ¸å¿ƒå­—æ®µ
    readonly tokenConsumer: T

    private readonly cstStack: SubhutiCst[] = []
    private readonly className: string

    // ============================================
    // æŒ‰éœ€è¯æ³•åˆ†æç›¸å…³å­—æ®µï¼ˆæ–°æ¶æ„ï¼‰
    // ============================================

    /** è¯æ³•åˆ†æå™¨ */
    protected _lexer: SubhutiLexer | null = null

    /** æºä»£ç  */
    protected _sourceCode: string = ''

    /** å½“å‰æºç ä½ç½® */
    protected _codeIndex: number = 0

    /** å½“å‰è¡Œå· */
    protected _codeLine: number = 1

    /** å½“å‰åˆ—å· */
    protected _codeColumn: number = 1

    /** ä¸Šä¸€ä¸ª token åç§°ï¼ˆç”¨äºä¸Šä¸‹æ–‡çº¦æŸï¼‰ */
    protected _lastTokenName: string | null = null

    /** æ¨¡æ¿å­—ç¬¦ä¸²æ·±åº¦ */
    protected _templateDepth: number = 0

    /** é»˜è®¤è¯æ³•ç›®æ ‡ */
    protected _defaultGoal: LexicalGoal = LexicalGoal.InputElementDiv

    /** Token ç¼“å­˜ï¼šä½ç½® â†’ æ¨¡å¼ â†’ ç¼“å­˜æ¡ç›® */
    protected _tokenCache: Map<number, Map<LexicalGoal, TokenCacheEntry>> = new Map()

    /** å·²è§£æçš„ token åˆ—è¡¨ï¼ˆç”¨äºè¾“å‡ºç»™ä½¿ç”¨è€…ï¼‰ */
    protected _parsedTokens: SubhutiMatchToken[] = []

    /**
     * åˆ†ææ¨¡å¼æ ‡å¿—
     * - true: åˆ†ææ¨¡å¼ï¼ˆç”¨äºè¯­æ³•éªŒè¯ï¼Œä¸æŠ›å¼‚å¸¸ï¼‰
     * - false: æ­£å¸¸æ¨¡å¼ï¼ˆç”¨äºè§£æï¼ŒæŠ›å¼‚å¸¸ï¼‰
     */
    private _analysisMode: boolean = false

    /**
     * å®¹é”™æ¨¡å¼æ ‡å¿—
     * - true: å¯ç”¨å®¹é”™ï¼ˆè§£æå¤±è´¥æ—¶è·³è¿‡ token ç»§ç»­è§£æï¼‰
     * - false: ä¸å¯ç”¨å®¹é”™ï¼ˆè§£æå¤±è´¥æ—¶åœæ­¢ï¼‰
     */
    private _errorRecoveryMode: boolean = false

    /**
     * åŒæ­¥ç‚¹ Token åç§°é›†åˆ
     * è¿™äº› token é€šå¸¸æ˜¯è¯­å¥çš„å¼€å§‹ï¼Œç”¨äºå®¹é”™æ¨¡å¼ä¸‹çš„æ¢å¤ç‚¹
     */
    protected _syncTokens: Set<string> = new Set([
        'LetTok', 'ConstTok', 'VarTok',
        'FunctionTok', 'ClassTok', 'AsyncTok',
        'IfTok', 'ForTok', 'WhileTok', 'DoTok', 'SwitchTok',
        'TryTok', 'ThrowTok', 'ReturnTok', 'BreakTok', 'ContinueTok',
        'ImportTok', 'ExportTok',
        'DebuggerTok',
        'Semicolon',
    ])

    /**
     * è®¾ç½®åŒæ­¥ç‚¹ Token
     */
    setSyncTokens(tokens: string[]): this {
        this._syncTokens = new Set(tokens)
        return this
    }

    /**
     * æ·»åŠ åŒæ­¥ç‚¹ Token
     */
    addSyncTokens(tokens: string[]): this {
        for (const token of tokens) {
            this._syncTokens.add(token)
        }
        return this
    }

    /**
     * å¯ç”¨å®¹é”™æ¨¡å¼
     */
    enableErrorRecovery(): this {
        this._errorRecoveryMode = true
        return this
    }

    /**
     * è·å–å®¹é”™æ¨¡å¼çŠ¶æ€
     */
    get errorRecoveryMode(): boolean {
        return this._errorRecoveryMode
    }

    getRuleStack() {
        return this.cstStack.map(item => item.name)
    }

    // è°ƒè¯•å’Œé”™è¯¯å¤„ç†
    private _debugger?: SubhutiTraceDebugger
    private readonly _errorHandler = new SubhutiErrorHandler()

    // æ— é™å¾ªç¯æ£€æµ‹ï¼ˆè°ƒç”¨æ ˆçŠ¶æ€æ£€æµ‹ï¼‰
    /**
     * å¾ªç¯æ£€æµ‹é›†åˆï¼šO(1) æ£€æµ‹ (rule, position) æ˜¯å¦é‡å¤
     * æ ¼å¼: "ruleName:position"
     */
    private readonly loopDetectionSet: Set<string> = new Set()

    // Packrat Parsingï¼ˆé»˜è®¤ LRU ç¼“å­˜ï¼‰
    enableMemoization: boolean = true
    private readonly _cache: SubhutiPackratCache

    /**
     * éƒ¨åˆ†åŒ¹é…å€™é€‰åˆ—è¡¨ï¼ˆå®¹é”™æ¨¡å¼ä¸“ç”¨ï¼‰
     * è®°å½•åœ¨å›æº¯æ—¶è¢«åˆ é™¤ä½†æ¶ˆè´¹äº† token çš„ CST ç‰‡æ®µ
     */
    private _partialMatchCandidates: PartialMatchRecord[] = []

    /**
     * æœªè¢«è§£æçš„ tokens åˆ—è¡¨ï¼ˆå®¹é”™æ¨¡å¼ä¸“ç”¨ï¼‰
     * ç”¨äºæœ€ç»ˆåˆ¤æ–­è§£ææ˜¯å¦å®Œå…¨æˆåŠŸ
     */
    private _unparsedTokens: SubhutiMatchToken[] = []

    // ============================================
    // è§£æè®°å½•æ ‘ç›¸å…³ï¼ˆå®¹é”™æ¨¡å¼ä¸“ç”¨ï¼‰
    // ============================================

    /** è§£æè®°å½•æ ‘æ ¹èŠ‚ç‚¹ */
    private _parseRecordRoot: ParseRecordNode | null = null

    /** è§£æè®°å½•æ ‘èŠ‚ç‚¹æ ˆï¼ˆè·Ÿè¸ªå½“å‰è·¯å¾„ï¼‰ */
    private _parseRecordStack: ParseRecordNode[] = []

    /**
     * è·å–æœªè¢«è§£æçš„ tokens åˆ—è¡¨
     */
    get unparsedTokens(): SubhutiMatchToken[] {
        return this._unparsedTokens
    }

    /**
     * æ˜¯å¦æœ‰æœªè¢«è§£æçš„ tokens
     */
    get hasUnparsedTokens(): boolean {
        return this._unparsedTokens.length > 0
    }

    /**
     * æ„é€ å‡½æ•° - æŒ‰éœ€è¯æ³•åˆ†ææ¨¡å¼
     *
     * @param sourceCode æºä»£ç 
     * @param options é…ç½®é€‰é¡¹
     */
    constructor(
        sourceCode: string = '',
        options?: SubhutiParserOptions<T>,
    ) {
        super()
        this.className = this.constructor.name
        this._cache = new SubhutiPackratCache()

        // åˆå§‹åŒ–æºä»£ç å’Œä½ç½®
        this._sourceCode = sourceCode
        this._codeIndex = 0
        this._codeLine = 1
        this._codeColumn = 1
        this._lastTokenName = null
        this._templateDepth = 0
        this._tokenCache = new Map()
        this._parsedTokens = []

        // åˆå§‹åŒ–è¯æ³•åˆ†æå™¨
        if (options?.tokenDefinitions) {
            this._lexer = new SubhutiLexer(options.tokenDefinitions)
        }

        // åˆå§‹åŒ– TokenConsumer
        if (options?.tokenConsumer) {
            this.tokenConsumer = new options.tokenConsumer(this)
        } else {
            this.tokenConsumer = new SubhutiTokenConsumer(this) as T
        }
    }

    /**
     * è·å–å·²è§£æçš„ token åˆ—è¡¨
     */
    get parsedTokens(): SubhutiMatchToken[] {
        return this._parsedTokens
    }

    /**
     * è·å–æœ€åè§£æçš„ token ç´¢å¼•
     * @returns token ç´¢å¼•ï¼Œå¦‚æœæ²¡æœ‰å·²è§£æçš„ token åˆ™è¿”å› -1
     */
    get lastTokenIndex(): number {
        return this._parsedTokens.length - 1
    }

    /**
     * è·å–å½“å‰æ­£åœ¨å¤„ç†çš„ token ç´¢å¼•ï¼ˆä¸‹ä¸€ä¸ªå°†è¢« consume çš„ tokenï¼‰
     * @returns å½“å‰ token ç´¢å¼•
     */
    get currentTokenIndex(): number {
        return this._parsedTokens.length
    }

    // ============================================
    // æŒ‰éœ€è¯æ³•åˆ†æ
    // ============================================

    /**
     * è·å–æˆ–è§£ææŒ‡å®šä½ç½®å’Œæ¨¡å¼çš„ token
     *
     * @param codeIndex æºç ä½ç½®
     * @param line è¡Œå·
     * @param column åˆ—å·
     * @param goal è¯æ³•ç›®æ ‡
     * @returns TokenCacheEntry æˆ– nullï¼ˆEOFï¼‰
     */
    protected _getOrParseToken(
        codeIndex: number,
        line: number,
        column: number,
        goal: LexicalGoal
    ): TokenCacheEntry | null {
        if (!this._lexer) return null

        // 1. æŸ¥ç¼“å­˜
        const positionCache = this._tokenCache.get(codeIndex)
        if (positionCache?.has(goal)) {
            return positionCache.get(goal)!
        }

        // 2. è§£ææ–° token
        const entry = this._lexer.readTokenAt(
            this._sourceCode,
            codeIndex,
            line,
            column,
            goal,
            this._lastTokenName,
            this._templateDepth
        )

        if (!entry) return null  // EOF

        // 3. å­˜å…¥ç¼“å­˜
        if (!positionCache) {
            this._tokenCache.set(codeIndex, new Map())
        }
        this._tokenCache.get(codeIndex)!.set(goal, entry)

        return entry
    }

    /**
     * LA (LookAhead) - å‰ç»è·å– tokenï¼ˆæ”¯æŒæ¨¡å¼æ•°ç»„ï¼‰
     *
     * @param offset åç§»é‡ï¼ˆ1 = å½“å‰ tokenï¼Œ2 = ä¸‹ä¸€ä¸ª...ï¼‰
     * @param goals æ¯ä¸ªä½ç½®çš„è¯æ³•ç›®æ ‡ï¼ˆå¯é€‰ï¼Œä¸ä¼ ç”¨é»˜è®¤å€¼ï¼‰
     * @returns token æˆ– undefinedï¼ˆEOFï¼‰
     */
    protected override LA(offset: number = 1, goals?: LexicalGoal[]): SubhutiMatchToken | undefined {
        let currentIndex = this._codeIndex
        let currentLine = this._codeLine
        let currentColumn = this._codeColumn

        for (let i = 0; i < offset; i++) {
            // ç¡®å®šå½“å‰ token çš„è¯æ³•ç›®æ ‡
            const goal = goals?.[i] ?? this._defaultGoal

            // ä»ç¼“å­˜è·å–æˆ–è§£æ
            const entry = this._getOrParseToken(currentIndex, currentLine, currentColumn, goal)

            if (!entry) return undefined  // EOF

            // å¦‚æœæ˜¯æœ€åä¸€ä¸ªï¼Œè¿”å› token
            if (i === offset - 1) {
                return entry.token
            }

            // å¦åˆ™ï¼Œç§»åŠ¨åˆ°ä¸‹ä¸€ä¸ªä½ç½®
            currentIndex = entry.nextCodeIndex
            currentLine = entry.nextLine
            currentColumn = entry.nextColumn
        }

        return undefined
    }

    /**
     * peek - å‰ç»è·å– tokenï¼ˆæ”¯æŒæ¨¡å¼æ•°ç»„ï¼‰
     */
    protected override peek(offset: number = 1, goals?: LexicalGoal[]): SubhutiMatchToken | undefined {
        return this.LA(offset, goals)
    }

    /**
     * è·å–å½“å‰ tokenï¼ˆä½¿ç”¨é»˜è®¤è¯æ³•ç›®æ ‡ï¼‰
     */
    override get curToken(): SubhutiMatchToken | undefined {
        return this.LA(1)
    }

    // ============================================
    // å…¬å¼€ç»™ TokenConsumer ä½¿ç”¨çš„æ–¹æ³•
    // ============================================

    /**
     * ä¾› TokenConsumer ä½¿ç”¨çš„ consume æ–¹æ³•
     * @param tokenName token åç§°
     * @param goal å¯é€‰çš„è¯æ³•ç›®æ ‡ï¼ˆç”¨äºæ¨¡æ¿å°¾éƒ¨ç­‰åœºæ™¯ï¼‰
     */
    _consumeToken(tokenName: string, goal?: LexicalGoal): SubhutiCst | undefined {
        return this.consume(tokenName, goal)
    }

    /**
     * ä¾› TokenConsumer ä½¿ç”¨çš„æ ‡è®°è§£æå¤±è´¥æ–¹æ³•
     * ç”¨äºè½¯å…³é”®å­—æ£€æŸ¥å¤±è´¥æ—¶æ ‡è®°è§£æå¤±è´¥
     */
    _markParseFail(): void {
        this._parseSuccess = false
    }

    // ============================================
    // Parser å†…éƒ¨ Getter
    // ============================================

    get curCst(): SubhutiCst | undefined {
        return this.cstStack[this.cstStack.length - 1]
    }

    // åŠŸèƒ½å¼€å…³ï¼ˆé“¾å¼è°ƒç”¨ï¼‰
    cache(enable: boolean = true): this {
        this.enableMemoization = enable
        return this
    }

    /**
     * å¯ç”¨è°ƒè¯•æ¨¡å¼
     * @param showRulePath - æ˜¯å¦æ˜¾ç¤ºè§„åˆ™æ‰§è¡Œè·¯å¾„ï¼ˆé»˜è®¤ trueï¼‰
     *                       ä¼ å…¥ false æ—¶åªæ˜¾ç¤ºæ€§èƒ½ç»Ÿè®¡å’Œ CST éªŒè¯æŠ¥å‘Š
     */
    debug(showRulePath: boolean = true): this {
        setShowRulePath(showRulePath)
        this._debugger = new SubhutiTraceDebugger(this._parsedTokens)
        return this
    }

    errorHandler(enable: boolean = true): this {
        this._errorHandler.setDetailed(enable)
        return this
    }

    /**
     * å¯ç”¨åˆ†ææ¨¡å¼ï¼ˆç”¨äºè¯­æ³•éªŒè¯ï¼Œä¸æŠ›å¼‚å¸¸ï¼‰
     *
     * åœ¨åˆ†ææ¨¡å¼ä¸‹ï¼š
     * - ä¸æŠ›å‡ºå·¦é€’å½’å¼‚å¸¸
     * - ä¸æŠ›å‡ºæ— é™å¾ªç¯å¼‚å¸¸
     * - ä¸æŠ›å‡º Token æ¶ˆè´¹å¤±è´¥å¼‚å¸¸
     * - ä¸æŠ›å‡º EOF æ£€æµ‹å¼‚å¸¸
     *
     * @internal ä»…ä¾› SubhutiRuleCollector ä½¿ç”¨
     */
    enableAnalysisMode(): void {
        this._analysisMode = true
    }

    /**
     * ç¦ç”¨åˆ†ææ¨¡å¼ï¼ˆæ¢å¤æ­£å¸¸æ¨¡å¼ï¼‰
     *
     * @internal ä»…ä¾› SubhutiRuleCollector ä½¿ç”¨
     */
    disableAnalysisMode(): void {
        this._analysisMode = false
    }

    /**
     * å¯ç”¨è¯­æ³•éªŒè¯ï¼ˆé“¾å¼è°ƒç”¨ï¼‰ï¼ŒéªŒè¯è¯­æ³•ï¼ˆæ£€æµ‹ Or è§„åˆ™å†²çªï¼‰
     *
     * ç”¨æ³•ï¼š
     * ```typescript
     * const parser = new Es2025Parser(tokens).validate()
     * const cst = parser.Script()
     * ```
     *
     * @returns this - æ”¯æŒé“¾å¼è°ƒç”¨
     * @throws SubhutiGrammarValidationError - è¯­æ³•æœ‰å†²çªæ—¶æŠ›å‡º
     */
    validate(): this {
        SubhutiGrammarValidator.validate(this)
        return this
    }

    /**
     * æ£€æµ‹æ˜¯å¦æ˜¯ç›´æ¥æˆ–é—´æ¥å·¦é€’å½’
     *
     * âœ… è¿™ä¸ªæ–¹æ³•å¯ä»¥å‡†ç¡®åˆ¤æ–­å·¦é€’å½’
     * âŒ ä¸èƒ½åˆ¤æ–­æ˜¯å¦æ˜¯ Or åˆ†æ”¯é®è”½ï¼ˆè¿”å› false åªè¡¨ç¤ºä¸æ˜¯å·¦é€’å½’ï¼‰
     *
     * @param ruleName å½“å‰è§„åˆ™åç§°
     * @param ruleStack è§„åˆ™è°ƒç”¨æ ˆ
     * @returns true: ç¡®å®šæ˜¯å·¦é€’å½’, false: ä¸æ˜¯å·¦é€’å½’ï¼ˆä½†ä¸èƒ½ç¡®å®šæ˜¯ä»€ä¹ˆé—®é¢˜ï¼‰
     */
    private isDirectLeftRecursion(ruleName: string, ruleStack: string[]): boolean {
        // æ£€æŸ¥è§„åˆ™æ ˆä¸­æ˜¯å¦æœ‰ä»»ä½•è§„åˆ™å‡ºç°äº† >= 2 æ¬¡
        // è¿™å¯ä»¥æ£€æµ‹ç›´æ¥å·¦é€’å½’å’Œé—´æ¥å·¦é€’å½’

        const ruleCounts = new Map<string, number>()

        for (const rule of ruleStack) {
            ruleCounts.set(rule, (ruleCounts.get(rule) || 0) + 1)
        }

        // å¦‚æœä»»ä½•è§„åˆ™å‡ºç° >= 2 æ¬¡ï¼Œè¯´æ˜æœ‰é€’å½’
        for (const count of ruleCounts.values()) {
            if (count >= 2) {
                return true  // âœ… ç¡®å®šæ˜¯å·¦é€’å½’ï¼ˆç›´æ¥æˆ–é—´æ¥ï¼‰
            }
        }

        // å¦åˆ™ï¼Œä¸æ˜¯å·¦é€’å½’
        // ä½†å¯èƒ½æ˜¯å…¶ä»–é—®é¢˜ï¼šOr åˆ†æ”¯é®è”½ã€è§„åˆ™å®ç°é”™è¯¯ã€è¯­æ³•é”™è¯¯ç­‰
        return false  // âŒ ä¸æ˜¯å·¦é€’å½’ï¼ˆä½†ä¸ç¡®å®šå…·ä½“æ˜¯ä»€ä¹ˆé—®é¢˜ï¼‰
    }

    /**
     * æŠ›å‡ºå¾ªç¯é”™è¯¯ä¿¡æ¯
     *
     * @param ruleName å½“å‰è§„åˆ™åç§°
     */
    private throwLoopError(ruleName: string): never {
        // ğŸ” åˆ†ææ¨¡å¼ï¼šä¸æŠ›å¼‚å¸¸ï¼Œç›´æ¥è¿”å›
        if (this._analysisMode) {
            // æ ‡è®°è§£æå¤±è´¥ï¼Œè®© RuleCollector çŸ¥é“è¿™ä¸ªè§„åˆ™æœ‰é—®é¢˜
            this._parseSuccess = false
            return undefined as never
        }

        // è·å–å½“å‰ token ä¿¡æ¯
        const currentToken = this.curToken

        // ä» parsedTokens è·å–ä¸Šä¸‹æ–‡ï¼ˆæœ€è¿‘ 2 ä¸ª tokenï¼‰
        const tokenContext = this.getTokenContext(2)

        // è·å–ç¼“å­˜ç»Ÿè®¡
        const cacheStatsReport = this._cache.getStatsReport()

        // ğŸ” åˆ†æå¾ªç¯ç±»å‹ï¼šçœŸæ­£çš„å·¦é€’å½’ vs Or åˆ†æ”¯é®è”½
        const ruleStack = this.getRuleStack()
        const isDirectLeftRecursion = this.isDirectLeftRecursion(ruleName, ruleStack)
        const errorType = isDirectLeftRecursion ? 'left-recursion' : 'or-branch-shadowing'

        // åˆ›å»ºå¾ªç¯é”™è¯¯ï¼ˆå¹³é“ºç»“æ„ï¼‰
        throw this._errorHandler.createError({
            type: errorType,
            expected: '',
            found: currentToken,
            position: {
                tokenIndex: this.currentTokenIndex,
                codeIndex: this._codeIndex,
                line: currentToken?.rowNum || this._codeLine,
                column: currentToken?.columnStartNum || this._codeColumn
            },
            ruleStack: [...ruleStack],
            loopRuleName: ruleName,
            loopDetectionSet: Array.from(this.loopDetectionSet),
            loopCstDepth: this.cstStack.length,
            loopCacheStats: {
                hits: cacheStatsReport.hits,
                misses: cacheStatsReport.misses,
                hitRate: cacheStatsReport.hitRate,
                currentSize: cacheStatsReport.currentSize
            },
            loopTokenContext: tokenContext,
            hint: 'æ£€æŸ¥è§„åˆ™å®šä¹‰ï¼Œç¡®ä¿åœ¨é€’å½’å‰æ¶ˆè´¹äº† token'
        })
    }

    /**
     * è§„åˆ™æ‰§è¡Œå…¥å£ï¼ˆç”± @SubhutiRule è£…é¥°å™¨è°ƒç”¨ï¼‰
     * èŒè´£ï¼šå‰ç½®æ£€æŸ¥ â†’ å¾ªç¯æ£€æµ‹ â†’ Packrat ç¼“å­˜ â†’ æ ¸å¿ƒæ‰§è¡Œ â†’ åç½®å¤„ç†
     */
    private executeRuleWrapper(targetFun: Function, ruleName: string, className: string, ...args: any[]): SubhutiCst | undefined {
        if (this.checkRuleIsThisClass(ruleName, className)) {
            return
        }
        const isTopLevel = this.cstStack.length === 0

        if (isTopLevel) {
            this.initTopLevelData()
        }

        if (this.parserFail) {
            return
        }

        const tokenIndex = this.currentTokenIndex
        const key = `${ruleName}:${tokenIndex}`

        // O(1) å¿«é€Ÿæ£€æµ‹æ˜¯å¦é‡å¤ï¼ˆå¾ªç¯æ£€æµ‹ï¼‰
        if (this.loopDetectionSet.has(key)) {
            this.throwLoopError(ruleName)
        }

        // å…¥æ ˆ
        this.loopDetectionSet.add(key)

        try {
            const startTime = this._debugger?.onRuleEnter(ruleName, tokenIndex)

            // Packrat Parsing ç¼“å­˜æŸ¥è¯¢
            if (this.enableMemoization) {
                const cached = this._cache.get(ruleName, tokenIndex)
                if (cached !== undefined) {
                    this._debugger?.onRuleExit(ruleName, true, startTime)

                    // è§£æè®°å½•æ¨¡å¼ï¼šç¼“å­˜å‘½ä¸­æ—¶ä¹Ÿè¦è®°å½•èŠ‚ç‚¹ï¼Œå¹¶æ›´æ–°æ•´ä¸ªç¥–å…ˆé“¾çš„ endTokenIndex
                    if (this.errorRecoveryMode && cached.endTokenIndex > tokenIndex) {
                        // åˆ›å»ºè®°å½•èŠ‚ç‚¹ï¼Œå¤åˆ¶ç¼“å­˜ä¸­çš„ children
                        const recordNode: ParseRecordNode = {
                            name: ruleName,
                            startTokenIndex: tokenIndex,
                            endTokenIndex: cached.endTokenIndex,
                            children: cached.recordNode?.children ? [...cached.recordNode.children] : []
                        }
                        const recordParent = this._parseRecordStack[this._parseRecordStack.length - 1]
                        if (recordParent) {
                            recordParent.children.push(recordNode)
                        }
                        // æ›´æ–°æ•´ä¸ªç¥–å…ˆé“¾çš„ endTokenIndex
                        for (let i = this._parseRecordStack.length - 1; i >= 0; i--) {
                            const ancestor = this._parseRecordStack[i]
                            if (cached.endTokenIndex > ancestor.endTokenIndex) {
                                ancestor.endTokenIndex = cached.endTokenIndex
                            }
                        }
                    }

                    const cst = this.applyCachedResult(cached)
                    if (!cst.children?.length) {
                        cst.children = undefined
                    }
                    return cst
                }
            }

            // æ ¸å¿ƒæ‰§è¡Œ
            const startTokenIndex = tokenIndex

            // è§£æè®°å½•æ ‘ï¼šåˆ›å»ºèŠ‚ç‚¹å¹¶å…¥æ ˆï¼ˆåœ¨ executeRuleCore ä¹‹å‰ï¼‰
            let recordNode: ParseRecordNode | null = null
            if (this.errorRecoveryMode) {
                recordNode = {
                    name: ruleName,
                    children: [],
                    startTokenIndex: tokenIndex,
                    endTokenIndex: tokenIndex
                }
                this._parseRecordStack.push(recordNode)
            }

            const cst = this.executeRuleCore(ruleName, targetFun, ...args)

            // è§£æè®°å½•æ ‘ï¼šå‡ºæ ˆï¼Œåªæœ‰æ¶ˆè´¹äº† token æ‰æ·»åŠ åˆ°çˆ¶èŠ‚ç‚¹
            if (this.errorRecoveryMode && recordNode) {
                this._parseRecordStack.pop()
                if (recordNode.endTokenIndex > recordNode.startTokenIndex) {
                    const recordParent = this._parseRecordStack[this._parseRecordStack.length - 1]
                    if (recordParent) {
                        recordParent.children.push(recordNode)
                    }
                }
            }

            // ç¼“å­˜å­˜å‚¨
            if (this.enableMemoization) {
                const endTokenIndex = this.currentTokenIndex
                const finalEndIndex = recordNode ? Math.max(recordNode.endTokenIndex, endTokenIndex) : endTokenIndex

                // æå–æœ¬æ¬¡è§„åˆ™æ¶ˆè´¹çš„ token
                const consumedTokens = this._parseSuccess
                    ? this._parsedTokens.slice(startTokenIndex)
                    : undefined

                this._cache.set(ruleName, startTokenIndex, {
                    endTokenIndex: finalEndIndex,
                    cst: cst,
                    parseSuccess: this._parseSuccess,
                    recordNode: recordNode,
                    parsedTokens: consumedTokens
                })
            }

            this.onRuleExitDebugHandler(ruleName, cst, isTopLevel, startTime)

            // é¡¶å±‚è§„åˆ™ï¼šæ£€æŸ¥æ˜¯å¦æ‰€æœ‰æºç éƒ½è¢«æ¶ˆè´¹
            if (isTopLevel && this._parseSuccess) {
                if (!this.isEof) {
                    const nextToken = this.LA(1)
                    throw new Error(
                        `Parser internal error: parsing succeeded but source code remains unconsumed. ` +
                        `Next token: "${nextToken?.tokenValue}" (${nextToken?.tokenName}) at position ${this._codeIndex}`
                    )
                }
            }

            // é¡¶å±‚è§„åˆ™å¤±è´¥æ—¶çš„é”™è¯¯å¤„ç†
            if (isTopLevel && this.parserFail) {
                this.handleTopLevelError(ruleName, startTokenIndex)
            }

            if (!cst.children?.length) {
                cst.children = undefined
            }
            return cst
        } finally {
            // å‡ºæ ˆï¼ˆæ— è®ºæˆåŠŸã€returnã€å¼‚å¸¸éƒ½ä¼šæ‰§è¡Œï¼‰
            this.loopDetectionSet.delete(key)
        }
    }

    private initTopLevelData() {
        // ã€é¡¶å±‚è§„åˆ™å¼€å§‹ã€‘é‡ç½®è§£æå™¨çŠ¶æ€
        this._parseSuccess = true
        this.cstStack.length = 0
        this.loopDetectionSet.clear()
        this._codeIndex = 0
        this._codeLine = 1
        this._codeColumn = 1
        this._parsedTokens = []
        this._tokenCache.clear()

        // é‡ç½®è°ƒè¯•å™¨çš„ç¼“å­˜å’Œç»Ÿè®¡
        this._debugger?.resetForNewParse?.(this._parsedTokens)
    }

    private checkRuleIsThisClass(ruleName: string, className: string): boolean {
        if (this.hasOwnProperty(ruleName)) {
            if (className !== this.className) {
                return true
            }
        }
    }

    private onRuleExitDebugHandler(
        ruleName: string,
        cst: SubhutiCst | undefined,
        isTopLevel: boolean,
        startTime?: number
    ): void {
        if (cst && !cst.children?.length) {
            cst.children = undefined
        }

        if (!isTopLevel) {
            this._debugger?.onRuleExit(ruleName, false, startTime)
        } else {
            // é¡¶å±‚è§„åˆ™å®Œæˆï¼Œè¾“å‡ºè°ƒè¯•ä¿¡æ¯
            if (this._debugger) {
                if ('setCst' in this._debugger) {
                    (this._debugger as any).setCst(cst)
                }
                (this._debugger as any)?.autoOutput?.()
            }
        }
    }

    /**
     * æ‰§è¡Œè§„åˆ™å‡½æ•°æ ¸å¿ƒé€»è¾‘
     * èŒè´£ï¼šåˆ›å»º CST â†’ æ‰§è¡Œè§„åˆ™ â†’ æˆåŠŸåˆ™æ·»åŠ åˆ°çˆ¶èŠ‚ç‚¹
     */
    private executeRuleCore(ruleName: string, targetFun: Function, ...args: any[]): SubhutiCst {
        const cst = new SubhutiCst()
        cst.name = ruleName
        cst.children = []

        this.cstStack.push(cst)

        // æ‰§è¡Œè§„åˆ™å‡½æ•°
        targetFun.apply(this, args)

        this.cstStack.pop()

        // æˆåŠŸæ—¶æ·»åŠ åˆ°çˆ¶èŠ‚ç‚¹å¹¶è®¾ç½®ä½ç½®
        if (this._parseSuccess) {
            const parentCst = this.cstStack[this.cstStack.length - 1]
            if (parentCst) {
                parentCst.children.push(cst)
            }
            this.setLocation(cst)
        }

        return cst
    }

    private setLocation(cst: SubhutiCst): void {
        if (cst.children && cst.children[0]?.loc) {
            const lastChild = cst.children[cst.children.length - 1]
            cst.loc = {
                type: cst.name,
                start: cst.children[0].loc.start,
                end: lastChild?.loc?.end || cst.children[0].loc.end
            }
        }
    }

    /**
     * Or è§„åˆ™ - é¡ºåºé€‰æ‹©ï¼ˆPEG é£æ ¼ï¼‰
     *
     * æ ¸å¿ƒé€»è¾‘ï¼š
     * - ä¾æ¬¡å°è¯•æ¯ä¸ªåˆ†æ”¯ï¼Œç¬¬ä¸€ä¸ªæˆåŠŸçš„åˆ†æ”¯ç”Ÿæ•ˆ
     * - æ‰€æœ‰åˆ†æ”¯éƒ½å¤±è´¥åˆ™æ•´ä½“å¤±è´¥
     *
     * ä¼˜åŒ–ï¼šåªæœ‰æ¶ˆè´¹äº† token æ‰éœ€è¦å›æº¯ï¼ˆæ²¡æ¶ˆè´¹ = çŠ¶æ€æ²¡å˜ï¼‰
     */
    Or(alternatives: SubhutiParserOr[]): void {
        if (this.parserFail) {
            return
        }

        const savedState = this.saveState()
        const startCodeIndex = this._codeIndex
        const totalCount = alternatives.length
        const parentRuleName = this.curCst?.name || 'Unknown'

        // è¿›å…¥ Orï¼ˆæ•´ä¸ª Or è°ƒç”¨å¼€å§‹ï¼‰
        this._debugger?.onOrEnter?.(parentRuleName, startCodeIndex)

        for (let i = 0; i < totalCount; i++) {
            const alt = alternatives[i]
            const isLast = i === totalCount - 1

            // è¿›å…¥ Or åˆ†æ”¯
            this._debugger?.onOrBranch?.(i, totalCount, parentRuleName)

            alt.alt()

            // é€€å‡º Or åˆ†æ”¯ï¼ˆæ— è®ºæˆåŠŸè¿˜æ˜¯å¤±è´¥ï¼‰
            this._debugger?.onOrBranchExit?.(parentRuleName, i)

            if (this._parseSuccess) {
                // é€€å‡º Orï¼ˆæ•´ä¸ª Or è°ƒç”¨æˆåŠŸç»“æŸï¼‰
                this._debugger?.onOrExit?.(parentRuleName)
                return
            }

            // å‰ N-1 ä¸ªåˆ†æ”¯ï¼šå¤±è´¥åå›æº¯å¹¶é‡ç½®çŠ¶æ€ï¼Œç»§ç»­å°è¯•ä¸‹ä¸€ä¸ª
            if (!isLast) {
                this.recordPartialMatchAndRestore(savedState, startCodeIndex)
                this._parseSuccess = true
            }
            // æœ€åä¸€ä¸ªåˆ†æ”¯ï¼šå¤±è´¥åä¸å›æº¯ï¼Œä¿æŒå¤±è´¥çŠ¶æ€
        }

        // é€€å‡º Orï¼ˆæ•´ä¸ª Or è°ƒç”¨å¤±è´¥ç»“æŸï¼‰
        this._debugger?.onOrExit?.(parentRuleName)
    }

    /**
     * Many è§„åˆ™ - 0æ¬¡æˆ–å¤šæ¬¡ï¼ˆEBNF { ... }ï¼‰
     *
     * å¾ªç¯æ‰§è¡Œç›´åˆ°å¤±è´¥æˆ–æ²¡æ¶ˆè´¹ token
     */
    Many(fn: RuleFunction): void {
        while (this.tryAndRestore(fn)) {
            // ç»§ç»­å¾ªç¯
        }
    }

    /**
     * å¸¦å®¹é”™çš„ Many è§„åˆ™ï¼ˆä½¿ç”¨è§£æè®°å½•æ ‘ï¼‰
     * - å½“å…¨å±€ errorRecoveryMode å¼€å¯æ—¶ï¼Œè§£æå¤±è´¥ä¼šå°è¯•æ¢å¤å¹¶ç»§ç»­
     * - ä½¿ç”¨è§£æè®°å½•æ ‘è®°å½•æ‰€æœ‰è§£æå°è¯•ï¼Œåªå¢ä¸åˆ 
     * - å¤±è´¥æ—¶ä»è§£æè®°å½•æ ‘æå–æœ€ä¼˜è·¯å¾„æ¢å¤ CST
     * @param fn è¦æ‰§è¡Œçš„è§„åˆ™å‡½æ•°
     */
    ManyWithRecovery(fn: RuleFunction): void {
        if (!this.errorRecoveryMode) {
            throw new Error('éå®¹é”™æ¨¡å¼ä¸åº”è¯¥è¿›å…¥ ManyWithRecovery')
        }

        // æ¸…ç†è®°å½•
        this._unparsedTokens.length = 0

        while (!this.parserFailOrIsEof) {
            const startTokenIndex = this.currentTokenIndex

            // å¯ç”¨è§£æè®°å½•ï¼Œä¸ºæœ¬æ¬¡è¿­ä»£åˆ›å»ºæ ¹èŠ‚ç‚¹
            this._parseRecordRoot = {
                name: '__ParseRecordRoot__',
                children: [],
                startTokenIndex: startTokenIndex,
                endTokenIndex: startTokenIndex
            }
            this._parseRecordStack = [this._parseRecordRoot]

            const success = this.tryAndRestore(fn)

            if (success) {
                // æˆåŠŸï¼Œæ¸…ç†è§£æè®°å½•æ ‘ï¼Œç»§ç»­ä¸‹ä¸€ä¸ª
                this._parseRecordRoot = null
                this._parseRecordStack = []
                continue
            }

            // è§£æå¤±è´¥ï¼Œå°è¯•ä»è§£æè®°å½•æ ‘æ¢å¤
            const syncIndex = this.findNextSyncPoint(this._codeIndex + 1)
            const recoveredCST = this.recoverFromParseRecord(this._parseRecordRoot!, syncIndex)

            if (recoveredCST && recoveredCST.children && recoveredCST.children.length > 0) {
                // æ¢å¤æˆåŠŸï¼Œå°† CST æ·»åŠ åˆ°å½“å‰èŠ‚ç‚¹
                const currentCst = this.curCst
                if (currentCst) {
                    currentCst.children.push(...recoveredCST.children)
                }
                // ä»æ¢å¤çš„ä½ç½®ç»§ç»­ï¼ˆéœ€è¦ä» parsedTokens æ¢å¤ codeIndexï¼‰
                const maxTokenIndex = this.getParseRecordMaxEndIndex(this._parseRecordRoot!, syncIndex)
                if (maxTokenIndex > 0 && maxTokenIndex <= this._parsedTokens.length) {
                    const lastToken = this._parsedTokens[maxTokenIndex - 1]
                    this._codeIndex = lastToken.index + lastToken.tokenValue.length
                }
            } else {
                // æ²¡æœ‰å¯æ¢å¤çš„å†…å®¹ï¼Œè·³è¿‡ä¸€ä¸ªå­—ç¬¦ç»§ç»­
                this._codeIndex++
            }

            // æ¸…ç†è§£æè®°å½•æ ‘
            this._parseRecordRoot = null
            this._parseRecordStack = []
            this._parseSuccess = true
        }

        // å‡ºå£ï¼šå¦‚æœæœ‰æœªè§£æçš„ tokensï¼Œæ ‡è®°è§£æå¤±è´¥
        if (this._unparsedTokens.length > 0) {
            this._parseSuccess = false
        }
    }

    /**
     * ä»è§£æè®°å½•æ ‘æ¢å¤ CST
     * æ‰¾åˆ° endTokenIndex <= maxIndex çš„æœ€æ·±è·¯å¾„ï¼Œè½¬æ¢ä¸º CST
     */
    private recoverFromParseRecord(root: ParseRecordNode, maxIndex: number): SubhutiCst | null {
        if (!root || root.children.length === 0) {
            return null
        }

        const cst = new SubhutiCst()
        cst.name = root.name
        cst.children = this.parseRecordChildrenToCST(root.children, maxIndex)

        if (!cst.children || cst.children.length === 0) {
            return null
        }

        return cst
    }

    /**
     * å°†è§£æè®°å½•æ ‘å­èŠ‚ç‚¹è½¬æ¢ä¸º CST å­èŠ‚ç‚¹
     *
     * é€‰æ‹©ç­–ç•¥ï¼š
     * 1. æŒ‰ startTokenIndex åˆ†ç»„ï¼ˆåŒä¸€ä½ç½®å¼€å§‹çš„æ˜¯ Or çš„ä¸åŒåˆ†æ”¯ï¼‰
     * 2. å¯¹äºæ¯ç»„ï¼Œé€‰æ‹© endTokenIndex <= maxIndex ä¸”æœ€å¤§çš„
     * 3. å¦‚æœæœ‰å¤šä¸ªç›¸åŒæ·±åº¦çš„ï¼Œé€‰æ‹©æœ€åä¸€ä¸ª
     */
    private parseRecordChildrenToCST(nodes: ParseRecordNode[], maxIndex: number): SubhutiCst[] {
        // æŒ‰ startTokenIndex åˆ†ç»„
        const groups = new Map<number, ParseRecordNode[]>()
        for (const node of nodes) {
            // è·³è¿‡è¶…è¿‡åŒæ­¥ç‚¹çš„èŠ‚ç‚¹
            if (node.endTokenIndex > maxIndex) {
                continue
            }
            const key = node.startTokenIndex
            if (!groups.has(key)) {
                groups.set(key, [])
            }
            groups.get(key)!.push(node)
        }

        // å¯¹æ¯ç»„é€‰æ‹©æœ€ä¼˜èŠ‚ç‚¹
        const selectedNodes: ParseRecordNode[] = []
        for (const [startIdx, group] of groups) {
            // é€‰æ‹© endTokenIndex æœ€å¤§çš„ï¼Œå¦‚æœç›¸åŒåˆ™é€‰æœ€åä¸€ä¸ªï¼ˆå…œåº•åˆ†æ”¯ï¼Œæ›´é€šç”¨ï¼‰
            let best: ParseRecordNode | null = null
            for (const node of group) {
                if (!best || node.endTokenIndex >= best.endTokenIndex) {
                    best = node
                }
            }
            if (best) {
                selectedNodes.push(best)
            }
        }

        // æŒ‰ startTokenIndex æ’åºï¼Œä¿è¯é¡ºåºæ­£ç¡®
        selectedNodes.sort((a, b) => a.startTokenIndex - b.startTokenIndex)

        // è½¬æ¢ä¸º CST
        return selectedNodes.map(node => this.parseRecordNodeToCST(node, maxIndex))
    }

    /**
     * å°†å•ä¸ªè§£æè®°å½•èŠ‚ç‚¹è½¬æ¢ä¸º CST èŠ‚ç‚¹
     */
    private parseRecordNodeToCST(node: ParseRecordNode, maxIndex: number): SubhutiCst {
        const cst = new SubhutiCst()
        cst.name = node.name

        // å¦‚æœæ˜¯ token èŠ‚ç‚¹
        if (node.token) {
            cst.value = node.value
            cst.loc = {
                type: node.token.tokenName,
                value: node.token.tokenValue,
                start: {
                    index: node.token.index || 0,
                    line: node.token.rowNum || 0,
                    column: node.token.columnStartNum || 0
                },
                end: {
                    index: (node.token.index || 0) + node.token.tokenValue.length,
                    line: node.token.rowNum || 0,
                    column: node.token.columnEndNum || 0
                }
            }
        }

        // é€’å½’è½¬æ¢å­èŠ‚ç‚¹
        if (node.children.length > 0) {
            cst.children = this.parseRecordChildrenToCST(node.children, maxIndex)
            if (cst.children.length === 0) {
                cst.children = undefined
            } else {
                // è®¾ç½®ä½ç½®ä¿¡æ¯
                this.setLocation(cst)
            }
        }

        return cst
    }

    /**
     * è·å–è§£æè®°å½•æ ‘ä¸­ <= maxIndex çš„æœ€å¤§ endTokenIndex
     */
    private getParseRecordMaxEndIndex(root: ParseRecordNode, maxIndex: number): number {
        let maxEnd = root.endTokenIndex <= maxIndex ? root.endTokenIndex : 0

        for (const child of root.children) {
            const childMax = this.getParseRecordMaxEndIndex(child, maxIndex)
            if (childMax > maxEnd) {
                maxEnd = childMax
            }
        }

        return maxEnd
    }

    /**
     * æ‰¾åˆ°ä¸‹ä¸€ä¸ªåŒæ­¥ç‚¹ï¼ˆè¯­å¥å¼€å§‹ tokenï¼‰
     * @param fromIndex ä»å“ªä¸ªæºç ä½ç½®å¼€å§‹æŸ¥æ‰¾
     * @returns åŒæ­¥ç‚¹çš„æºç ä½ç½®ï¼Œå¦‚æœæ²¡æ‰¾åˆ°è¿”å›æºç æœ«å°¾
     */
    protected findNextSyncPoint(fromIndex: number): number {
        // ä»æŒ‡å®šä½ç½®å¼€å§‹ï¼Œå°è¯•è§£ææ¯ä¸ªä½ç½®çš„ token
        for (let i = fromIndex; i < this._sourceCode.length; i++) {
            const entry = this._getOrParseToken(i, this._codeLine, this._codeColumn, this._defaultGoal)
            if (entry && this._syncTokens.has(entry.token.tokenName)) {
                return i
            }
        }
        return this._sourceCode.length  // æ²¡æ‰¾åˆ°ï¼Œè¿”å›æºç æœ«å°¾
    }

    /**
     * åˆ›å»º ErrorNodeï¼ŒåŒ…å«æŒ‡å®šèŒƒå›´å†…çš„ token
     * @param startIndex èµ·å§‹æºç ä½ç½®ï¼ˆåŒ…å«ï¼‰
     * @param endIndex ç»“æŸæºç ä½ç½®ï¼ˆä¸åŒ…å«ï¼‰
     * @returns ErrorNode CST èŠ‚ç‚¹
     */
    protected createErrorNode(startIndex: number, endIndex: number): SubhutiCst {
        const errorNode = new SubhutiCst()
        errorNode.name = 'ErrorNode'
        errorNode.children = []

        // ä» parsedTokens ä¸­æ‰¾å‡ºåœ¨èŒƒå›´å†…çš„ tokens
        for (const token of this._parsedTokens) {
            if (token.index >= startIndex && token.index < endIndex) {
                const tokenNode = new SubhutiCst()
                tokenNode.name = token.tokenName
                tokenNode.value = token.tokenValue
                tokenNode.loc = {
                    type: token.tokenName,
                    value: token.tokenValue,
                    start: {
                        index: token.index,
                        line: token.rowNum,
                        column: token.columnStartNum
                    },
                    end: {
                        index: token.index + (token.tokenValue?.length || 0),
                        line: token.rowNum,
                        column: token.columnEndNum
                    }
                }
                errorNode.children.push(tokenNode)
            }
        }

        // è®¾ç½® ErrorNode çš„ä½ç½®ä¿¡æ¯
        if (errorNode.children.length > 0) {
            const first = errorNode.children[0]
            const last = errorNode.children[errorNode.children.length - 1]
            errorNode.loc = {
                type: 'ErrorNode',
                start: first.loc.start,
                end: last.loc.end
            }
        }

        return errorNode
    }

    /**
     * Option è§„åˆ™ - 0æ¬¡æˆ–1æ¬¡ï¼ˆEBNF [ ... ]ï¼‰
     *
     * å°è¯•æ‰§è¡Œä¸€æ¬¡ï¼Œå¤±è´¥åˆ™å›æº¯ï¼Œä¸å½±å“æ•´ä½“è§£æçŠ¶æ€
     */
    Option(fn: RuleFunction): void {
        this.tryAndRestore(fn)
    }

    /**
     * AtLeastOne è§„åˆ™ - 1æ¬¡æˆ–å¤šæ¬¡
     *
     * ç¬¬ä¸€æ¬¡å¿…é¡»æˆåŠŸï¼Œåç»­å¾ªç¯æ‰§è¡Œç›´åˆ°å¤±è´¥
     */
    AtLeastOne(fn: RuleFunction): void {
        if (this.parserFail) {
            return
        }

        fn()

        while (this.tryAndRestore(fn)) {
            // ç»§ç»­å¾ªç¯
        }
    }

    /**
     * é¡¶å±‚è§„åˆ™å¤±è´¥æ—¶çš„é”™è¯¯å¤„ç†
     *
     * @param ruleName è§„åˆ™å
     * @param startIndex è§„åˆ™å¼€å§‹æ—¶çš„æºç ä½ç½®
     */
    private handleTopLevelError(ruleName: string, startIndex: number): void {
        // åˆ†ææ¨¡å¼ï¼šä¸æŠ›é”™ï¼Œç”¨äºè¯­æ³•éªŒè¯
        if (this._analysisMode) {
            return
        }

        // æ­£å¸¸æ¨¡å¼ï¼šæŠ›å‡ºè§£æé”™è¯¯
        const noTokenConsumed = this.currentTokenIndex === startIndex
        const found = this.curToken

        throw this._errorHandler.createError({
            type: 'parsing',
            expected: noTokenConsumed ? 'valid syntax' : 'EOF (end of file)',
            found: found,
            position: {
                tokenIndex: this.currentTokenIndex,
                codeIndex: this._codeIndex,
                line: found?.rowNum ?? this._codeLine,
                column: found?.columnStartNum ?? this._codeColumn
            },
            ruleStack: this.getRuleStack().length > 0 ? this.getRuleStack() : [ruleName]
        })
    }

    get parserFailOrIsEof() {
        return this.parserFail || this.isEof
    }

    /**
     * æ¶ˆè´¹ tokenï¼ˆæ™ºèƒ½é”™è¯¯ç®¡ç†ï¼‰
     * - å¤±è´¥æ—¶è¿”å› undefinedï¼Œä¸æŠ›å¼‚å¸¸
     * - æ”¯æŒä¼ å…¥è¯æ³•ç›®æ ‡ï¼ˆå¯é€‰ï¼‰
     */
    consume(tokenName: string, goal?: LexicalGoal): SubhutiCst | undefined {
        if (this.parserFail) {
            return
        }

        if (this.isEof) {
            this._parseSuccess = false
            return
        }

        // è·å–å½“å‰ token
        const actualGoal = goal ?? this._defaultGoal
        const entry = this._getOrParseToken(
            this._codeIndex,
            this._codeLine,
            this._codeColumn,
            actualGoal
        )

        if (!entry) {
            this._parseSuccess = false
            return
        }

        const token = entry.token

        if (token.tokenName !== tokenName) {
            this._parseSuccess = false

            this._debugger?.onTokenConsume(
                this._codeIndex,
                token.tokenValue,
                token.tokenName,
                tokenName,
                false
            )

            return
        }

        this._debugger?.onTokenConsume(
            this._codeIndex,
            token.tokenValue,
            token.tokenName,
            tokenName,
            true
        )

        const cst = this.generateCstByToken(token)

        // æ›´æ–°æ¨¡æ¿æ·±åº¦
        if (token.tokenName === 'TemplateHead') {
            this._templateDepth++
        } else if (token.tokenName === 'TemplateTail') {
            this._templateDepth--
        }

        // æ›´æ–°ä½ç½®
        this._codeIndex = entry.nextCodeIndex
        this._codeLine = entry.nextLine
        this._codeColumn = entry.nextColumn
        this._lastTokenName = entry.lastTokenName

        // æ·»åŠ åˆ°å·²è§£æåˆ—è¡¨
        this._parsedTokens.push(token)

        return cst
    }

    private generateCstByToken(token: SubhutiMatchToken): SubhutiCst {
        const cst = new SubhutiCst()
        cst.name = token.tokenName
        cst.value = token.tokenValue
        cst.loc = {
            type: token.tokenName,
            value: token.tokenValue,
            start: {
                index: token.index || 0,
                line: token.rowNum || 0,
                column: token.columnStartNum || 0
            },
            end: {
                index: (token.index || 0) + token.tokenValue.length,
                line: token.rowNum || 0,
                column: token.columnEndNum || 0
            }
        }

        // æ·»åŠ åˆ°å½“å‰ CST
        const currentCst = this.curCst
        if (currentCst) {
            currentCst.children.push(cst)
        }

        // è§£æè®°å½•æ ‘ï¼šè®°å½• token å¹¶æ›´æ–°ç¥–å…ˆçš„ endTokenIndex
        if (this.errorRecoveryMode) {
            const newEndIndex = this.currentTokenIndex  // consume åä¼š +1
            const tokenNode: ParseRecordNode = {
                name: token.tokenName,
                children: [],
                startTokenIndex: this.lastTokenIndex,  // consume åçš„ç´¢å¼•
                endTokenIndex: newEndIndex,
                token: token,
                value: token.tokenValue
            }
            const recordCurrent = this._parseRecordStack[this._parseRecordStack.length - 1]
            if (recordCurrent) {
                recordCurrent.children.push(tokenNode)
            }
            // æ›´æ–°æ‰€æœ‰ç¥–å…ˆçš„ endTokenIndex
            for (const ancestor of this._parseRecordStack) {
                ancestor.endTokenIndex = newEndIndex
            }
        }

        return cst
    }

    // å›æº¯æœºåˆ¶
    private saveState(): SubhutiBackData {
        const currentCst = this.curCst
        return {
            codeIndex: this._codeIndex,
            codeLine: this._codeLine,
            codeColumn: this._codeColumn,
            lastTokenName: this._lastTokenName,
            curCstChildrenLength: currentCst?.children?.length || 0,
            parsedTokensLength: this._parsedTokens.length
        }
    }

    private restoreState(backData: SubhutiBackData): void {
        const fromIndex = this._codeIndex
        const toIndex = backData.codeIndex

        if (fromIndex !== toIndex) {
            this._debugger?.onBacktrack?.(fromIndex, toIndex)
        }

        this._codeIndex = backData.codeIndex
        this._codeLine = backData.codeLine
        this._codeColumn = backData.codeColumn
        this._lastTokenName = backData.lastTokenName

        // æ¢å¤ parsedTokens
        this._parsedTokens.length = backData.parsedTokensLength

        const currentCst = this.curCst
        if (currentCst) {
            currentCst.children.length = backData.curCstChildrenLength
        }
    }

    /**
     * ã€å®¹é”™æ¨¡å¼ã€‘è®°å½•éƒ¨åˆ†åŒ¹é…å¹¶å›æº¯
     * - è§£æè®°å½•æ ‘æ–¹æ¡ˆä¸­ï¼Œéƒ¨åˆ†åŒ¹é…ç”± _parseRecordRoot è®°å½•
     * - è¿™é‡Œåªéœ€è¦å›æº¯ CSTï¼ˆè§£æè®°å½•æ ‘æ˜¯åªå¢ä¸åˆ çš„ï¼‰
     *
     * @param savedState ä¿å­˜çš„çŠ¶æ€
     * @param startCodeIndex èµ·å§‹æºç ä½ç½®
     */
    private recordPartialMatchAndRestore(savedState: SubhutiBackData, startCodeIndex: number): void {
        this.restoreState(savedState)
    }

    /**
     * æ£€æŸ¥æ˜¯å¦å·²åˆ°è¾¾æºç æœ«å°¾
     */
    get isEof(): boolean {
        const entry = this._getOrParseToken(
            this._codeIndex,
            this._codeLine,
            this._codeColumn,
            this._defaultGoal
        )
        return entry === null
    }

    /**
     * å°è¯•æ‰§è¡Œå‡½æ•°ï¼Œå¤±è´¥æ—¶è‡ªåŠ¨å›æº¯å¹¶é‡ç½®çŠ¶æ€
     *
     * @param fn è¦æ‰§è¡Œçš„å‡½æ•°
     * @returns true: æˆåŠŸä¸”æ¶ˆè´¹äº† tokenï¼Œfalse: å¤±è´¥æˆ–æ²¡æ¶ˆè´¹ token
     */
    private tryAndRestore(fn: () => void): boolean {
        if (this.parserFailOrIsEof) {
            return false
        }
        const savedState = this.saveState()
        const startIndex = this._codeIndex

        fn()

        if (this.parserFail) {
            // è®°å½•éƒ¨åˆ†åŒ¹é…å¹¶å›æº¯
            this.recordPartialMatchAndRestore(savedState, startIndex)
            this._parseSuccess = true
            return false
        }

        // æˆåŠŸä½†æ²¡æ¶ˆè´¹ token â†’ è¿”å› falseï¼ˆé˜²æ­¢æ— é™å¾ªç¯ï¼‰
        return this._codeIndex !== startIndex
    }

    /**
     * åº”ç”¨ç¼“å­˜ç»“æœï¼ˆæ¢å¤çŠ¶æ€ï¼‰
     */
    private applyCachedResult(cached: SubhutiPackratCacheResult): SubhutiCst {
        // æ¢å¤æ¶ˆè´¹çš„ token
        if (cached.parsedTokens && cached.parsedTokens.length > 0) {
            this._parsedTokens.push(...cached.parsedTokens)

            // ä»æœ€åä¸€ä¸ª token æ¢å¤è¯æ³•åˆ†æä½ç½®
            const lastToken = cached.parsedTokens[cached.parsedTokens.length - 1]
            this._codeIndex = lastToken.index + lastToken.tokenValue.length
            this._codeLine = lastToken.rowNum
            this._codeColumn = lastToken.columnEndNum
            this._lastTokenName = lastToken.tokenName
        }

        this._parseSuccess = cached.parseSuccess

        // æˆåŠŸæ—¶æ·»åŠ åˆ°çˆ¶èŠ‚ç‚¹
        if (cached.parseSuccess) {
            const parentCst = this.cstStack[this.cstStack.length - 1]
            if (parentCst) {
                parentCst.children.push(cached.cst)
            }
        }

        return cached.cst
    }

    // ============================================
    // Error Helper Methods
    // ============================================

    /**
     * è·å– token ä¸Šä¸‹æ–‡ï¼ˆä» parsedTokens è·å–æœ€è¿‘çš„ N ä¸ª tokenï¼‰
     *
     * @param contextSize - ä¸Šä¸‹æ–‡å¤§å°ï¼ˆé»˜è®¤ 2ï¼‰
     * @returns token ä¸Šä¸‹æ–‡æ•°ç»„
     */
    private getTokenContext(contextSize: number = 2): SubhutiMatchToken[] {
        const tokens = this._parsedTokens
        const len = tokens.length
        const start = Math.max(0, len - contextSize)
        return tokens.slice(start)
    }

    /**
     * ç”Ÿæˆå½“å‰è§„åˆ™è·¯å¾„çš„å­—ç¬¦ä¸²ï¼ˆç”¨äºé”™è¯¯ä¿¡æ¯ï¼‰
     *
     * @returns æ ¼å¼åŒ–åçš„è§„åˆ™è·¯å¾„å­—ç¬¦ä¸²æ•°ç»„
     */
    private formatCurrentRulePath(): string[] {
        if (!this._debugger) {
            // å¦‚æœæ²¡æœ‰è°ƒè¯•å™¨ï¼Œä½¿ç”¨ç®€å•æ ¼å¼
            return this.formatSimpleRulePath()
        }

        // ä½¿ç”¨è°ƒè¯•å™¨çš„æ ¼å¼åŒ–æ–¹æ³•
        const ruleStack = this._debugger.ruleStack
        if (!ruleStack || ruleStack.length === 0) {
            return ['  (empty)']
        }

        return SubhutiDebugRuleTracePrint.formatPendingOutputs_NonCache_Impl(ruleStack)
    }

    /**
     * ç®€å•æ ¼å¼åŒ–è§„åˆ™è·¯å¾„ï¼ˆå½“æ²¡æœ‰è°ƒè¯•å™¨æ—¶ï¼‰
     */
    private formatSimpleRulePath(): string[] {
        const ruleStack = this.getRuleStack()
        if (ruleStack.length === 0) {
            return ['  (empty)']
        }

        const lines: string[] = []
        for (let i = 0; i < ruleStack.length; i++) {
            const rule = ruleStack[i]
            const isLast = i === ruleStack.length - 1
            const indent = '  '.repeat(i)
            const connector = i === 0 ? '' : 'â””â”€ '
            const marker = isLast ? ' â† å½“å‰ä½ç½®' : ''

            lines.push(`  ${indent}${connector}${rule}${marker}`)
        }

        return lines
    }

    /**
     * åˆ›å»ºæ— é™å¾ªç¯é”™è¯¯
     *
     * @param ruleName - è§„åˆ™åç§°
     * @param hint - ä¿®å¤æç¤º
     * @returns ParsingError å®ä¾‹ï¼ˆåˆ†ææ¨¡å¼ä¸‹è¿”å› nullï¼‰
     */
    private createInfiniteLoopError(ruleName: string, hint: string): ParsingError {
        // ğŸ” åˆ†ææ¨¡å¼ï¼šä¸åˆ›å»ºé”™è¯¯ï¼Œæ ‡è®°å¤±è´¥å¹¶è¿”å› null
        if (this._analysisMode) {
            this._parseSuccess = false
            return null as any  // åˆ†ææ¨¡å¼ä¸‹ä¸ä¼šçœŸæ­£ä½¿ç”¨è¿™ä¸ªè¿”å›å€¼
        }

        // ç”Ÿæˆè§„åˆ™è·¯å¾„
        const rulePathLines = this.formatCurrentRulePath()
        const rulePath = rulePathLines.join('\n')

        // ğŸ” æ£€æµ‹æ˜¯å¦æ˜¯å·¦é€’å½’ï¼ˆå‡†ç¡®åˆ¤æ–­ï¼‰
        const ruleStack = this.getRuleStack()
        const isLeftRecursion = this.isDirectLeftRecursion(ruleName, ruleStack)

        // âœ… åªæœ‰ç¡®å®šæ˜¯å·¦é€’å½’æ—¶æ‰ä½¿ç”¨ 'left-recursion' ç±»å‹
        // âŒ ä¸ç¡®å®šçš„æƒ…å†µä½¿ç”¨ 'infinite-loop'ï¼Œä¸æ–­è¨€æ˜¯ Or é®è”½
        const errorType = isLeftRecursion ? 'left-recursion' : 'infinite-loop'

        return this._errorHandler.createError({
            type: errorType,
            expected: '',
            found: this.curToken,
            position: {
                tokenIndex: this.currentTokenIndex,
                codeIndex: this._codeIndex,
                line: this.curToken?.rowNum || this._codeLine,
                column: this.curToken?.columnStartNum || this._codeColumn
            },
            ruleStack: [...ruleStack],
            loopRuleName: ruleName,
            loopDetectionSet: [],
            loopCstDepth: this.cstStack.length,
            loopTokenContext: this.getTokenContext(2),
            hint: hint,
            rulePath: rulePath
        })
    }
}

