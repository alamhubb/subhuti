# Subhuti

[![npm version](https://img.shields.io/npm/v/subhuti.svg)](https://www.npmjs.com/package/subhuti)
[![License: MIT](https://img.shields.io/badge/License-MIT-blue.svg)](https://opensource.org/licenses/MIT)

**Subhuti (à¤¸à¥à¤­à¥‚à¤¤à¤¿)** - è½»é‡çº§ã€é«˜æ€§èƒ½çš„ PEG Parser Generator æ¡†æ¶ï¼Œç”¨ TypeScript æ„å»ºï¼Œä¸“ä¸ºå¿«é€Ÿå¼€å‘ç¼–ç¨‹è¯­è¨€è§£æå™¨è€Œè®¾è®¡ã€‚

**åç§°ç”±æ¥ï¼š** Subhutiï¼ˆè©æç¥–å¸ˆï¼‰æ˜¯å­™æ‚Ÿç©ºçš„å¸ˆçˆ¶ï¼Œå¯“æ„è®©ç¼–ç¨‹è¯­è¨€è½¬æ¢å¦‚ä¸ƒåäºŒå˜èˆ¬çµæ´»ã€‚

## âœ¨ æ ¸å¿ƒç‰¹æ€§

### ğŸš€ é«˜æ€§èƒ½ Packrat Parsing
- **çº¿æ€§æ—¶é—´å¤æ‚åº¦ O(n)**ï¼šé€šè¿‡ LRU ç¼“å­˜é¿å…é‡å¤è§£æ
- **æ™ºèƒ½ç¼“å­˜ç®¡ç†**ï¼šè‡ªåŠ¨æ¸…ç†è¿‡æœŸç¼“å­˜ï¼Œå†…å­˜å ç”¨å¯æ§
- **å¯é€‰å¼€å…³**ï¼šæ ¹æ®éœ€æ±‚çµæ´»å¯ç”¨/ç¦ç”¨ç¼“å­˜

### ğŸ¯ PEG é£æ ¼è¯­æ³•ï¼ˆParsing Expression Grammarï¼‰
- **é¡ºåºé€‰æ‹©**ï¼š`Or` è§„åˆ™æŒ‰é¡ºåºå°è¯•ï¼Œç¬¬ä¸€ä¸ªæˆåŠŸå³è¿”å›
- **è‡ªåŠ¨å›æº¯**ï¼šå¤±è´¥æ—¶è‡ªåŠ¨æ¢å¤çŠ¶æ€ï¼Œæ”¯æŒå¤æ‚è¯­æ³•
- **æ¸…æ™°è¯­ä¹‰**ï¼šç¨‹åºå‘˜å®Œå…¨æ§åˆ¶è§„åˆ™é¡ºåºï¼Œæ— äºŒä¹‰æ€§

### ğŸ›¡ï¸ æ™ºèƒ½é”™è¯¯ç®¡ç†ï¼ˆallowError æœºåˆ¶ï¼‰
- **å‰ N-1 åˆ†æ”¯å…è®¸å¤±è´¥**ï¼šåœ¨ `Or` è§„åˆ™ä¸­ä¼˜é›…å¤„ç†å¤±è´¥
- **æœ€ååˆ†æ”¯æŠ›è¯¦ç»†é”™è¯¯**ï¼šç²¾ç¡®å®šä½è¯­æ³•é”™è¯¯ï¼Œé™„å¸¦å®Œæ•´ä¸Šä¸‹æ–‡
- **RAII æ¨¡å¼ç®¡ç†**ï¼šè‡ªåŠ¨æ¢å¤é”™è¯¯çŠ¶æ€ï¼Œé¿å…æ‰‹åŠ¨ç®¡ç†

### ğŸ¨ ä¼˜é›…çš„ TypeScript API
- **è£…é¥°å™¨æ¨¡å¼**ï¼šä½¿ç”¨ `@SubhutiRule` å®šä¹‰è§„åˆ™ï¼Œä»£ç ç®€æ´
- **å¼ºç±»å‹æ”¯æŒ**ï¼šå®Œæ•´çš„ TypeScript ç±»å‹å®šä¹‰
- **é“¾å¼è°ƒç”¨**ï¼šæµç•…çš„ API è®¾è®¡ï¼ˆ`.cache().debug().errorHandler()`ï¼‰

### ğŸ”§ å¼€å‘å‹å¥½
- **è°ƒè¯•æ”¯æŒ**ï¼šå†…ç½® Trace Debuggerï¼Œå¯è§†åŒ–è§„åˆ™åŒ¹é…è¿‡ç¨‹
- **é”™è¯¯å¤„ç†**ï¼šè¯¦ç»†çš„é”™è¯¯ä¿¡æ¯ï¼ˆä½ç½®ã€æœŸæœ›ã€å®é™…ã€è§„åˆ™æ ˆï¼‰
- **é—®é¢˜æ£€æµ‹ç³»ç»Ÿ**ï¼šè¿è¡Œæ—¶æ£€æµ‹å·¦é€’å½’ã€æ— é™å¾ªç¯ç­‰å¸¸è§é”™è¯¯ â­ æ–°åŠŸèƒ½
- **è¯­æ³•éªŒè¯**ï¼šè‡ªåŠ¨æ£€æµ‹ Or è§„åˆ™å†²çªï¼ˆå‰ç¼€é®è”½ã€ç©ºè·¯å¾„ï¼‰â­ æ–°åŠŸèƒ½
- **CST è¾…åŠ©æ–¹æ³•**ï¼š`getChild()`, `getChildren()`, `getToken()` ç­‰ä¾¿æ·æ–¹æ³•
- **Token å‰ç»**ï¼šå®Œæ•´æ”¯æŒ ECMAScript è§„èŒƒçš„æ‰€æœ‰ `[lookahead ...]` çº¦æŸ â­ æ–°åŠŸèƒ½

## ğŸ“¦ å®‰è£…

```bash
npm install subhuti
# æˆ–
yarn add subhuti
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å®šä¹‰ Lexerï¼ˆè¯æ³•åˆ†æå™¨ï¼‰

```typescript
import { SubhutiLexer, createKeywordToken, createRegToken, createValueRegToken } from 'subhuti'

// å®šä¹‰ Token
const tokens = [
  // å…³é”®å­—
  createKeywordToken('IfTok', 'if'),
  createKeywordToken('ElseTok', 'else'),
  createKeywordToken('ReturnTok', 'return'),

  // æ ‡è¯†ç¬¦å’Œå­—é¢é‡
  createRegToken('Identifier', /[a-zA-Z_][a-zA-Z0-9_]*/),
  createRegToken('Number', /[0-9]+/),

  // ç¬¦å·
  createKeywordToken('LParen', '('),
  createKeywordToken('RParen', ')'),
  createKeywordToken('Semicolon', ';'),

  // è·³è¿‡ç©ºæ ¼å’Œæ³¨é‡Šï¼ˆskip: trueï¼‰
  createValueRegToken('WhiteSpace', /[ \t\r\n]+/, '', true),
  createValueRegToken('Comment', /\/\/[^\n]*/, '', true),
]

// åˆ›å»º Lexer
const lexer = new SubhutiLexer(tokens)

// åˆ†è¯
const sourceCode = 'if (x) return 42;'
const tokenStream = lexer.tokenize(sourceCode)
```

### 2. å®šä¹‰ TokenConsumerï¼ˆå¯é€‰ï¼Œç®€åŒ– token æ¶ˆè´¹ï¼‰

```typescript
import { SubhutiTokenConsumer } from 'subhuti'

// è‡ªå®šä¹‰ TokenConsumerï¼Œä¸ºæ¯ä¸ª token åˆ›å»ºä¾¿æ·æ–¹æ³•
class MyTokenConsumer extends SubhutiTokenConsumer {
  IfTok() { return this.consume(tokens.find(t => t.name === 'IfTok')!) }
  ElseTok() { return this.consume(tokens.find(t => t.name === 'ElseTok')!) }
  ReturnTok() { return this.consume(tokens.find(t => t.name === 'ReturnTok')!) }
  Identifier() { return this.consume(tokens.find(t => t.name === 'Identifier')!) }
  Number() { return this.consume(tokens.find(t => t.name === 'Number')!) }
  LParen() { return this.consume(tokens.find(t => t.name === 'LParen')!) }
  RParen() { return this.consume(tokens.find(t => t.name === 'RParen')!) }
  Semicolon() { return this.consume(tokens.find(t => t.name === 'Semicolon')!) }
}
```

### 3. å®šä¹‰ Parserï¼ˆè¯­æ³•åˆ†æå™¨ï¼‰

```typescript
import { SubhutiParser, SubhutiRule, Subhuti } from 'subhuti'

@Subhuti
class MyParser extends SubhutiParser<MyTokenConsumer> {
  constructor(tokens) {
    super(tokens, MyTokenConsumer)  // ä¼ å…¥è‡ªå®šä¹‰ TokenConsumer
  }

  @SubhutiRule
  Statement() {
    this.Or([
      { alt: () => this.IfStatement() },
      { alt: () => this.ReturnStatement() },
      { alt: () => this.ExpressionStatement() }
    ])
  }

  @SubhutiRule
  IfStatement() {
    this.tokenConsumer.IfTok()      // ä½¿ç”¨ TokenConsumer çš„ä¾¿æ·æ–¹æ³•
    this.tokenConsumer.LParen()
    this.Expression()
    this.tokenConsumer.RParen()
    this.Statement()

    // å¯é€‰çš„ else åˆ†æ”¯
    this.Option(() => {
      this.tokenConsumer.ElseTok()
      this.Statement()
    })
  }

  @SubhutiRule
  ReturnStatement() {
    this.tokenConsumer.ReturnTok()
    this.Expression()
    this.tokenConsumer.Semicolon()
  }

  @SubhutiRule
  Expression() {
    // ç®€åŒ–ç¤ºä¾‹
    this.Or([
      { alt: () => this.tokenConsumer.Identifier() },
      { alt: () => this.tokenConsumer.Number() }
    ])
  }

  @SubhutiRule
  ExpressionStatement() {
    this.Expression()
    this.tokenConsumer.Semicolon()
  }
}
```

### 4. è§£æä»£ç 

```typescript
const parser = new MyParser(tokenStream)
  .cache(true)          // å¯ç”¨ Packrat ç¼“å­˜
  .debug(false)         // ç”Ÿäº§ç¯å¢ƒå…³é—­è°ƒè¯•
  .errorHandler(true)   // å¯ç”¨è¯¦ç»†é”™è¯¯ä¿¡æ¯

// è§£æ
const cst = parser.Statement()

// è®¿é—® CST
if (cst) {
  console.log('è§„åˆ™åç§°:', cst.name)
  console.log('å­èŠ‚ç‚¹æ•°é‡:', cst.childCount)

  // ä½¿ç”¨ä¾¿æ·æ–¹æ³•è®¿é—®
  const condition = cst.getChild('Expression')
  const returnValue = cst.getToken('Number')

  // è®¿é—®ä½ç½®ä¿¡æ¯ï¼ˆç”¨äºé”™è¯¯æŠ¥å‘Šã€æºç æ˜ å°„ï¼‰
  console.log('ä½ç½®:', cst.loc.start.line, cst.loc.start.column)
}
```

## ğŸ“– æ ¸å¿ƒèƒ½åŠ›

### Lexer é«˜çº§ç‰¹æ€§

#### è¯æ³•å±‚å‰ç»ï¼ˆLexical Lookaheadï¼‰

å¤„ç†è¯æ³•æ­§ä¹‰ï¼Œå¦‚ `?.` (å¯é€‰é“¾) vs `?` (ä¸‰å…ƒè¿ç®—ç¬¦)ï¼š

```typescript
import { createValueRegToken } from 'subhuti'

const tokens = [
  // å¯é€‰é“¾ï¼š?. åé¢ä¸èƒ½æ˜¯æ•°å­—
  createValueRegToken('OptionalChaining', /\?\./, '?.', false, {
    not: /[0-9]/  // lookaheadAfter: åé¢ä¸èƒ½æ˜¯æ•°å­—
  }),

  // ä¸‰å…ƒè¿ç®—ç¬¦
  createKeywordToken('Question', '?'),
  createKeywordToken('Dot', '.'),
]

// ä»£ç : "obj?.prop" â†’ OptionalChaining
// ä»£ç : "a ? .5 : 1" â†’ Question, Dot, Number
```

#### æ¨¡æ¿å­—ç¬¦ä¸²æ”¯æŒ

è‡ªåŠ¨å¤„ç† ECMAScript çš„ InputElement åˆ‡æ¢ï¼š

```typescript
// Lexer è‡ªåŠ¨è¯†åˆ«æ¨¡æ¿å­—ç¬¦ä¸²çš„ä¸Šä¸‹æ–‡
const code = '`Hello ${name}!`'
const tokens = lexer.tokenize(code)
// â†’ TemplateHead(`Hello ${`), Identifier(name), TemplateTail(`}!`)
```

#### è·³è¿‡ Token

è‡ªåŠ¨è¿‡æ»¤ç©ºæ ¼ã€æ³¨é‡Šç­‰ï¼š

```typescript
createValueRegToken('WhiteSpace', /[ \t\r\n]+/, '', true),  // skip: true
createValueRegToken('LineComment', /\/\/[^\n]*/, '', true),
createValueRegToken('BlockComment', /\/\*[\s\S]*?\*\//, '', true),
```

### Parser ç»„åˆå™¨

#### `Or` - é¡ºåºé€‰æ‹©ï¼ˆ**è§„åˆ™é¡ºåºå¾ˆé‡è¦ï¼**ï¼‰

```typescript
this.Or([
  { alt: () => { /* é•¿è§„åˆ™ï¼šä¼˜å…ˆå°è¯• */ } },
  { alt: () => { /* çŸ­è§„åˆ™ï¼šä½œä¸ºå›é€€ */ } }
])
```

âš ï¸ **å…³é”®åŸåˆ™**ï¼š**é•¿è§„åˆ™å¿…é¡»åœ¨çŸ­è§„åˆ™å‰é¢**

```typescript
// âŒ é”™è¯¯ç¤ºä¾‹ï¼ˆçŸ­è§„åˆ™åœ¨å‰ï¼‰
ImportSpecifier() {
  this.Or([
    { alt: () => this.ImportedBinding() },        // çŸ­ï¼šname
    { alt: () => {                                 // é•¿ï¼šname as userName
      this.Identifier()
      this.AsTok()
      this.ImportedBinding()
    }}
  ])
}
// é—®é¢˜ï¼šé‡åˆ° "name as userName" æ—¶ï¼Œç¬¬ä¸€ä¸ªåˆ†æ”¯åŒ¹é… "name" åç«‹å³è¿”å›
// å‰©ä½™ "as userName" å¯¼è‡´ä¸Šå±‚è§„åˆ™å¤±è´¥

// âœ… æ­£ç¡®ç¤ºä¾‹ï¼ˆé•¿è§„åˆ™åœ¨å‰ï¼‰
ImportSpecifier() {
  this.Or([
    { alt: () => {                                 // é•¿è§„åˆ™ä¼˜å…ˆ
      this.Identifier()
      this.AsTok()
      this.ImportedBinding()
    }},
    { alt: () => this.ImportedBinding() }         // çŸ­è§„åˆ™å›é€€
  ])
}
```

#### `Many` - 0 æ¬¡æˆ–å¤šæ¬¡

```typescript
this.Many(() => {
  this.Statement()
})
```

#### `AtLeastOne` - 1 æ¬¡æˆ–å¤šæ¬¡

```typescript
this.AtLeastOne(() => {
  this.Parameter()
})
```

#### `Option` - 0 æ¬¡æˆ– 1 æ¬¡

```typescript
this.Option(() => {
  this.ElseClause()
})
```

### Token å‰ç»ï¼ˆLookaheadï¼‰

Subhuti æä¾›äº†å¼ºå¤§çš„ Token å‰ç»åŠŸèƒ½ï¼Œå¯¹åº” ECMAScript è§„èŒƒä¸­çš„ `[lookahead ...]` çº¦æŸã€‚

#### æŸ¥è¯¢æ–¹æ³•ï¼ˆç”¨äºæ¡ä»¶åˆ¤æ–­ï¼‰

```typescript
// æ£€æŸ¥ä¸‹ä¸€ä¸ª token æ˜¯å¦åŒ¹é…
if (this.lookahead('LBrace', 1)) {
  // ä¸‹ä¸€ä¸ªæ˜¯ {
}

// æ£€æŸ¥ä¸‹ä¸€ä¸ª token æ˜¯å¦ä¸åŒ¹é…
if (this.lookaheadNot('ElseTok', 1)) {
  // ä¸‹ä¸€ä¸ªä¸æ˜¯ else
}

// æ£€æŸ¥æ˜¯å¦åœ¨é›†åˆä¸­
if (this.lookaheadIn(['FunctionTok', 'ClassTok'], 1)) {
  // ä¸‹ä¸€ä¸ªæ˜¯ function æˆ– class
}

// æ£€æŸ¥æ˜¯å¦ä¸åœ¨é›†åˆä¸­
if (this.lookaheadNotIn(['LBrace', 'FunctionTok'], 1)) {
  // ä¸‹ä¸€ä¸ªæ—¢ä¸æ˜¯ { ä¹Ÿä¸æ˜¯ function
}

// æ£€æŸ¥ token åºåˆ—
if (this.lookaheadSequence(['AsyncTok', 'FunctionTok'])) {
  // æ¥ä¸‹æ¥æ˜¯ async function
}

// æ£€æŸ¥åºåˆ—ä¸”ä¸­é—´æ— æ¢è¡Œç¬¦
if (this.lookaheadSequenceNoLT(['AsyncTok', 'FunctionTok'])) {
  // async [no LineTerminator here] function
}
```

#### æ–­è¨€æ–¹æ³•ï¼ˆç”¨äºå‰ç»çº¦æŸï¼‰

æ–­è¨€æ–¹æ³•ä¼šè‡ªåŠ¨è®¾ç½®è§£æçŠ¶æ€ï¼Œå¤±è´¥æ—¶æ ‡è®°å½“å‰åˆ†æ”¯å¤±è´¥ï¼š

```typescript
@SubhutiRule
ExpressionStatement() {
  // [lookahead âˆ‰ {{, function, class}]
  this.assertLookaheadNotIn(['LBrace', 'FunctionTok', 'ClassTok'])

  // [lookahead â‰  let []
  this.assertLookaheadNotSequence(['LetTok', 'LBracket'])

  this.Expression({ In: true })
  this.SemicolonASI()
}

@SubhutiRule
ArrowFunction() {
  this.AsyncTok()

  // [no LineTerminator here]
  this.assertNoLineBreak()

  this.ArrowParameters()
}
```

**å¯¹åº” ECMAScript è§„èŒƒï¼š**
- `[lookahead = token]` â†’ `assertLookahead('token')`
- `[lookahead â‰  token]` â†’ `assertLookaheadNot('token')`
- `[lookahead âˆˆ {t1, t2}]` â†’ `assertLookaheadIn(['t1', 't2'])`
- `[lookahead âˆ‰ {t1, t2}]` â†’ `assertLookaheadNotIn(['t1', 't2'])`
- `[lookahead = t1 t2]` â†’ `assertLookaheadSequence(['t1', 't2'])`
- `[lookahead â‰  t1 t2]` â†’ `assertLookaheadNotSequence(['t1', 't2'])`
- `[no LineTerminator here]` â†’ `assertNoLineBreak()`

### CST è¾…åŠ©æ–¹æ³•

```typescript
// è·å–ç¬¬ N ä¸ªæŒ‡å®šåç§°çš„å­èŠ‚ç‚¹
const leftExpr = cst.getChild('Expression', 0)
const rightExpr = cst.getChild('Expression', 1)

// è·å–æ‰€æœ‰æŒ‡å®šåç§°çš„å­èŠ‚ç‚¹
const allStatements = cst.getChildren('Statement')

// è·å– Token èŠ‚ç‚¹
const identifier = cst.getToken('Identifier')
console.log(identifier?.value)  // token çš„å€¼

// æ£€æŸ¥æ˜¯å¦å­˜åœ¨å­èŠ‚ç‚¹
if (cst.hasChild('ElseClause')) {
  // å¤„ç† else åˆ†æ”¯
}

// å±æ€§
cst.childCount  // å­èŠ‚ç‚¹æ•°é‡
cst.isToken     // æ˜¯å¦ä¸º token èŠ‚ç‚¹
cst.isEmpty     // æ˜¯å¦ä¸ºç©ºèŠ‚ç‚¹
```

### ä½ç½®ä¿¡æ¯ï¼ˆSource Locationï¼‰

æ¯ä¸ª CST èŠ‚ç‚¹éƒ½åŒ…å«å®Œæ•´çš„ä½ç½®ä¿¡æ¯ï¼Œç”¨äºé”™è¯¯æŠ¥å‘Šå’Œæºç æ˜ å°„ï¼š

```typescript
const cst = parser.Statement()

// è®¿é—®ä½ç½®ä¿¡æ¯
console.log(cst.loc.start)  // { index: 0, line: 1, column: 0 }
console.log(cst.loc.end)    // { index: 15, line: 1, column: 15 }

// Token èŠ‚ç‚¹è¿˜åŒ…å«å€¼
const identifier = cst.getToken('Identifier')
console.log(identifier?.value)  // token çš„æ–‡æœ¬å€¼
console.log(identifier?.loc.start.line)  // token æ‰€åœ¨è¡Œå·
```

### è‡ªå®šä¹‰å¤±è´¥æ ‡è®°ï¼ˆparserFailï¼‰

åœ¨è‡ªå®šä¹‰éªŒè¯é€»è¾‘ä¸­æ ‡è®°è§£æå¤±è´¥ï¼š

```typescript
@SubhutiRule
Identifier() {
  const cst = this.tokenConsumer.Identifier()

  // è‡ªå®šä¹‰éªŒè¯ï¼šä¿ç•™å­—æ£€æŸ¥
  if (cst && ReservedWords.has(cst.value!)) {
    return this.parserFail()  // æ ‡è®°å¤±è´¥ï¼Œè§¦å‘å›æº¯
  }

  return cst
}
```

### åŠ¨æ€æ›´æ¢ Token æµ

é‡ç”¨ Parser å®ä¾‹è§£æå¤šä¸ªæ–‡ä»¶ï¼š

```typescript
const parser = new MyParser([])

// è§£æç¬¬ä¸€ä¸ªæ–‡ä»¶
parser.setTokens(lexer.tokenize(code1))
const cst1 = parser.Script()

// è§£æç¬¬äºŒä¸ªæ–‡ä»¶
parser.setTokens(lexer.tokenize(code2))
const cst2 = parser.Script()
```

### åŠŸèƒ½å¼€å…³ï¼ˆé“¾å¼è°ƒç”¨ï¼‰

```typescript
const parser = new MyParser(tokenStream)
  .cache(true)          // å¯ç”¨ Packrat ç¼“å­˜ï¼ˆé»˜è®¤å¼€å¯ï¼‰
  .debug(true)          // å¯ç”¨è°ƒè¯•è¾“å‡º
  .errorHandler(true)   // å¯ç”¨è¯¦ç»†é”™è¯¯ä¿¡æ¯
```

### è¯­æ³•éªŒè¯ï¼ˆGrammar Validationï¼‰â­ æ–°åŠŸèƒ½

**è‡ªåŠ¨æ£€æµ‹ Or è§„åˆ™å†²çª**ï¼Œé¿å…çŸ­è§„åˆ™é®è”½é•¿è§„åˆ™çš„é—®é¢˜ï¼

```typescript
// æ£€æŸ¥è¯­æ³•æ˜¯å¦æ­£ç¡®
const result = parser.validateGrammar()

if (!result.success) {
  console.error('å‘ç°è¯­æ³•å†²çª:', result.errors)
  // [
  //   {
  //     level: 'ERROR',
  //     type: 'prefix-conflict',
  //     ruleName: 'Expression',
  //     branchIndices: [0, 1],
  //     conflictPaths: {
  //       pathA: 'Identifier,',               // çŸ­è·¯å¾„
  //       pathB: 'Identifier,Dot,Identifier,' // é•¿è·¯å¾„ï¼ˆè¢«é®è”½ï¼‰
  //     },
  //     message: 'åˆ†æ”¯ 1 (MemberExpression) è¢«åˆ†æ”¯ 0 (Identifier) é®è”½',
  //     suggestion: 'å°† MemberExpression ç§»åˆ° Identifier å‰é¢'
  //   }
  // ]
}

// ä¸¥æ ¼æ¨¡å¼ï¼ˆå‘ç°é”™è¯¯å°±æŠ›å‡ºå¼‚å¸¸ï¼‰
parser.validateGrammar({ strict: true })

// è¯¦ç»†è¾“å‡ºï¼ˆæ‰“å°æ‰€æœ‰é”™è¯¯ï¼‰
parser.validateGrammar({ verbose: true })

// å¿½ç•¥ç‰¹å®šè§„åˆ™
parser.validateGrammar({ ignoreRules: ['LegacyRule'] })
```

**æ£€æµ‹è§„åˆ™ï¼š**
1. **ç©ºè·¯å¾„å†²çªï¼ˆFATALï¼‰**ï¼š`Option`/`Many` åœ¨ Or ç¬¬ä¸€ä¸ªåˆ†æ”¯ï¼Œå¯¼è‡´åç»­åˆ†æ”¯ä¸å¯è¾¾
2. **å‰ç¼€å†²çªï¼ˆERRORï¼‰**ï¼šçŸ­è§„åˆ™åœ¨å‰ï¼Œé®è”½é•¿è§„åˆ™

**æ¨èä½¿ç”¨åœºæ™¯ï¼š**
- âœ… å¼€å‘é˜¶æ®µï¼šåœ¨æµ‹è¯•ä¸­è‡ªåŠ¨éªŒè¯è¯­æ³•
- âœ… CI/CDï¼šé˜²æ­¢é”™è¯¯çš„è§„åˆ™é¡ºåºåˆå…¥ä»£ç 
- âœ… é‡æ„ï¼šç¡®ä¿ä¿®æ”¹ä¸å¼•å…¥å†²çª

```typescript
// ç¤ºä¾‹ï¼šåœ¨æµ‹è¯•ä¸­ä½¿ç”¨
describe('Parser Grammar', () => {
  it('should not have Or conflicts', () => {
    const parser = new MyParser([])
    const result = parser.validateGrammar()
    expect(result.success).toBe(true)
  })
})
```

## ğŸ”¬ Or å†²çªæ£€æµ‹ç³»ç»Ÿ - æ ¸å¿ƒè®¾è®¡

Subhuti çš„ Or å†²çªæ£€æµ‹ç³»ç»Ÿæ˜¯ä¸€ä¸ªåˆ›æ–°çš„é™æ€åˆ†æå·¥å…·ï¼Œèƒ½å¤Ÿåœ¨å¼€å‘é˜¶æ®µè‡ªåŠ¨å‘ç° PEG è¯­æ³•ä¸­çš„å¸¸è§é—®é¢˜ã€‚

### è®¾è®¡ç†å¿µ

**é—®é¢˜**ï¼šPEG çš„é¡ºåºé€‰æ‹©ç‰¹æ€§ä½¿å¾—è§„åˆ™é¡ºåºè‡³å…³é‡è¦ï¼Œä½†æ‰‹åŠ¨æ£€æŸ¥æ‰€æœ‰ Or è§„åˆ™éå¸¸å›°éš¾ä¸”å®¹æ˜“å‡ºé”™ã€‚

**è§£å†³æ–¹æ¡ˆ**ï¼šé€šè¿‡ AST åˆ†æå’Œè·¯å¾„å±•å¼€ï¼Œè‡ªåŠ¨æ£€æµ‹ Or åˆ†æ”¯ä¹‹é—´çš„å†²çªã€‚

### æ ¸å¿ƒç®—æ³•

#### 1. AST æ”¶é›†ï¼ˆRule Collectionï¼‰

ä½¿ç”¨ Proxy æ‹¦æˆªè§„åˆ™è°ƒç”¨ï¼Œè‡ªåŠ¨æ„å»ºè¯­æ³•çš„ AST è¡¨ç¤ºï¼š

```typescript
// è‡ªåŠ¨æ”¶é›†è§„åˆ™å®šä¹‰
const ruleASTs = SubhutiRuleCollector.collectRules(parser)

// ç”Ÿæˆçš„ AST ç»“æ„
{
  "Expression": {
    type: "or",
    alternatives: [
      { type: "subrule", ruleName: "PrimaryExpression" },
      { type: "subrule", ruleName: "BinaryExpression" }
    ]
  }
}
```

**å…³é”®æŠ€æœ¯**ï¼š
- Proxy æ‹¦æˆªï¼šæ— éœ€ä¿®æ”¹ Parser ä»£ç 
- é”™è¯¯å®¹å¿ï¼šå³ä½¿è§„åˆ™æ‰§è¡Œå¤±è´¥ä¹Ÿèƒ½æ”¶é›† AST
- å®Œæ•´æ€§ï¼šæ•è·æ‰€æœ‰è§„åˆ™è°ƒç”¨ï¼ˆOrã€Manyã€Optionã€Sequence ç­‰ï¼‰

#### 2. åˆ†æ”¯å±•å¼€ï¼ˆBranch Expansionï¼‰

å°†æ¯ä¸ª Or åˆ†æ”¯å±•å¼€ä¸ºæ‰€æœ‰å¯èƒ½çš„ token è·¯å¾„ï¼š

```typescript
// è§„åˆ™å®šä¹‰
Or([
  { alt: () => {
    this.Identifier()
    this.Option(() => this.Dot())
    this.Identifier()
  }},
  { alt: () => this.Number() }
])

// å±•å¼€ç»“æœ
åˆ†æ”¯ 0: [
  ["Identifier", "Identifier"],      // ä¸åŒ¹é… Dot
  ["Identifier", "Dot", "Identifier"] // åŒ¹é… Dot
]
åˆ†æ”¯ 1: [
  ["Number"]
]
```

**å±•å¼€ç­–ç•¥**ï¼š
- **Token/Rule**ï¼šä¸å±•å¼€ï¼Œä¿æŒåŸæ ·
- **Sequence**ï¼šç¬›å¡å°”ç§¯ç»„åˆæ‰€æœ‰å­èŠ‚ç‚¹
- **Or**ï¼šåˆå¹¶æ‰€æœ‰åˆ†æ”¯
- **Option/Many**ï¼šç”Ÿæˆç©ºè·¯å¾„ + å†…éƒ¨åˆ†æ”¯
- **AtLeastOne**ï¼šç”Ÿæˆ 1æ¬¡ + 2æ¬¡é‡å¤

**å±‚çº§æ§åˆ¶**ï¼š
```typescript
// æ”¯æŒå¤šå±‚å±•å¼€
getExpandChildren(ruleName, maxLevel, curLevel)

// ç¤ºä¾‹ï¼šmaxLevel = 2
Rule1 â†’ Rule2 â†’ Token  // å±•å¼€ 2 å±‚
Rule1 â†’ Rule2 â†’ Rule3  // ç¬¬ 3 å±‚åœæ­¢ï¼Œä¿ç•™ Rule3
```

#### 3. å†²çªæ£€æµ‹ï¼ˆConflict Detectionï¼‰

##### 3.1 å‰ç¼€å†²çªæ£€æµ‹

æ£€æµ‹çŸ­è§„åˆ™æ˜¯å¦é®è”½é•¿è§„åˆ™ï¼š

```typescript
// æ£€æµ‹é€»è¾‘
for (pathA of branchA) {
  for (pathB of branchB) {
    if (pathA.length < pathB.length && pathB.startsWith(pathA)) {
      // å‘ç°å‰ç¼€å†²çªï¼
      // pathA ä¼šå…ˆåŒ¹é…ï¼Œå¯¼è‡´ pathB æ°¸è¿œæ— æ³•å®Œæ•´åŒ¹é…
    }
  }
}
```

**ç¤ºä¾‹**ï¼š
```typescript
Or([
  { alt: () => this.Identifier() },           // åˆ†æ”¯ 0: ["Identifier"]
  { alt: () => {                              // åˆ†æ”¯ 1: ["Identifier", "Dot", "Identifier"]
    this.Identifier()
    this.Dot()
    this.Identifier()
  }}
])

// æ£€æµ‹ç»“æœï¼š
// âŒ åˆ†æ”¯ 1 è¢«åˆ†æ”¯ 0 é®è”½
// Path A: Identifier,
// Path B: Identifier,Dot,Identifier,
```

##### 3.2 ç©ºè·¯å¾„å†²çªæ£€æµ‹ï¼ˆé¡¶å±‚æ£€æµ‹ï¼‰

æ£€æµ‹ Or åˆ†æ”¯æœ¬èº«æ˜¯å¦å¯ä»¥åŒ¹é…ç©ºè¾“å…¥ï¼š

```typescript
/**
 * é¡¶å±‚ç©ºè·¯å¾„æ£€æµ‹ - åªæ£€æµ‹åˆ†æ”¯çš„é¡¶å±‚ç»“æ„
 *
 * çœŸæ­£çš„é—®é¢˜ï¼š
 * Or([
 *   { alt: () => this.Option(() => this.A()) },  // âŒ åˆ†æ”¯æœ¬èº«å¯ä»¥ä¸ºç©º
 *   { alt: () => this.B() }                       // æ°¸è¿œä¸å¯è¾¾
 * ])
 *
 * ä¸æ˜¯é—®é¢˜ï¼š
 * Or([
 *   { alt: () => {
 *     this.X()                                    // âœ… å¿…é¡»å…ˆåŒ¹é… X
 *     this.Option(() => this.A())                 // å†…éƒ¨çš„ Option ä¸å½±å“
 *   }},
 *   { alt: () => this.B() }
 * ])
 */
hasTopLevelEmptyPath(alternative) {
  switch (alternative.type) {
    case 'option':
    case 'many':
      return true  // ç›´æ¥æ˜¯ Option/Manyï¼Œå¯ä»¥ä¸ºç©º

    case 'sequence':
      // æ£€æŸ¥ç¬¬ä¸€ä¸ªå…ƒç´ 
      return this.hasTopLevelEmptyPath(alternative.nodes[0])

    case 'or':
      // ä»»ä¸€å­åˆ†æ”¯å¯ä»¥ä¸ºç©º
      return alternative.alternatives.some(alt =>
        this.hasTopLevelEmptyPath(alt)
      )

    default:
      return false  // token/rule/atLeastOne ä¸èƒ½ä¸ºç©º
  }
}
```

**å…³é”®åŒºåˆ«**ï¼š
- âŒ **æ—§é€»è¾‘**ï¼šæ£€æµ‹å±•å¼€åçš„è·¯å¾„ä¸­æ˜¯å¦æœ‰ç©ºè·¯å¾„ï¼ˆè¯¯æŠ¥ï¼‰
- âœ… **æ–°é€»è¾‘**ï¼šåªæ£€æµ‹åˆ†æ”¯é¡¶å±‚ç»“æ„æ˜¯å¦å¯ä»¥ä¸ºç©ºï¼ˆç²¾å‡†ï¼‰

#### 4. ä»£ç å¤ç”¨è®¾è®¡

é€šè¿‡æå–å…¬å…±æ–¹æ³•ï¼Œå®ç°ä»£ç å¤ç”¨ï¼š

```typescript
/**
 * å…¬å…±æ–¹æ³•ï¼šè®¡ç®— Or åˆ†æ”¯çš„å®Œå…¨å±•å¼€ç»“æœ
 *
 * è¢«ä»¥ä¸‹æ£€æµ‹å…±ç”¨ï¼š
 * - ç©ºè·¯å¾„æ£€æµ‹
 * - å‰ç¼€å†²çªæ£€æµ‹
 * - æœªæ¥çš„å…¶ä»–æ£€æµ‹ï¼ˆLL(k)ã€äºŒä¹‰æ€§ç­‰ï¼‰
 */
computeOrBranchExpansions(alternatives) {
  // æ­¥éª¤1: è·å–ç›´æ¥å­èŠ‚ç‚¹ï¼ˆå±•å¼€è¾…åŠ©èŠ‚ç‚¹ï¼‰
  const directChildren = computeDirectChildren(alternative)

  // æ­¥éª¤2: å¯¹æ¯ä¸ªè§„åˆ™ä»ç¼“å­˜ä¸­è·å–å±•å¼€ç»“æœ
  const expandedItems = branch.map(item =>
    getExpansionFromCache(item) || [[item]]
  )

  // æ­¥éª¤3: ç¬›å¡å°”ç§¯åˆå¹¶
  return cartesianProduct(expandedItems)
}

// ä½¿ç”¨å…¬å…±æ–¹æ³•
detectOrConflicts(alternatives) {
  const branchExpansions = computeOrBranchExpansions(alternatives)

  // æ‰§è¡Œå„ç§æ£€æµ‹
  checkEmptyPath(branchExpansions)
  checkPrefixConflict(branchExpansions)
}
```

**ä¼˜åŠ¿**ï¼š
- æ•°æ®è®¡ç®—é€»è¾‘ç»Ÿä¸€
- æ·»åŠ æ–°æ£€æµ‹ç±»å‹æ—¶ç›´æ¥å¤ç”¨
- ä¿®æ”¹å±•å¼€é€»è¾‘æ—¶æ‰€æœ‰æ£€æµ‹è‡ªåŠ¨å—ç›Š

### æ€§èƒ½ä¼˜åŒ–

#### 1. ç¼“å­˜æœºåˆ¶

```typescript
// ç›´æ¥å­èŠ‚ç‚¹ç¼“å­˜
directChildrenCache: Map<ruleName, branches>

// å®Œå…¨å±•å¼€ç¼“å­˜
expansionCache: Map<ruleName, expandedBranches>
```

#### 2. å¾ªç¯å¼•ç”¨æ£€æµ‹

```typescript
// ä½¿ç”¨ computing é›†åˆæ£€æµ‹é€’å½’
computing: Set<ruleName>

getExpandChildren(ruleName) {
  if (computing.has(ruleName)) {
    return [[ruleName]]  // é‡åˆ°å¾ªç¯ï¼Œåœæ­¢å±•å¼€
  }
  computing.add(ruleName)
  try {
    // å±•å¼€é€»è¾‘
  } finally {
    computing.delete(ruleName)
  }
}
```

#### 3. åˆ†æ”¯æ•°é‡é™åˆ¶

é˜²æ­¢ç¬›å¡å°”ç§¯çˆ†ç‚¸ï¼š

```typescript
// é™åˆ¶å•ä¸ªè§„åˆ™çš„åˆ†æ”¯æ•°
if (branches.length > 1000) {
  console.warn(`è§„åˆ™ ${ruleName} çš„åˆ†æ”¯æ•°è¿‡å¤šï¼Œæˆªæ–­`)
  return branches.slice(0, 1000)
}

// é™åˆ¶å±•å¼€ç»“æœæ•°é‡
if (expandedBranches.length > 1000) {
  return expandedBranches.slice(0, 1000)
}
```

### é”™è¯¯çº§åˆ«

- **FATAL**ï¼šç©ºè·¯å¾„å†²çª - å¯¼è‡´åç»­åˆ†æ”¯å®Œå…¨ä¸å¯è¾¾
- **ERROR**ï¼šå‰ç¼€å†²çª - å¯¼è‡´é•¿è§„åˆ™æ— æ³•å®Œæ•´åŒ¹é…
- **WARNING**ï¼šï¼ˆæœªæ¥ï¼‰æ½œåœ¨æ€§èƒ½é—®é¢˜

### ä½¿ç”¨å»ºè®®

**å¼€å‘é˜¶æ®µ**ï¼š
```typescript
// åœ¨æµ‹è¯•ä¸­è‡ªåŠ¨éªŒè¯
describe('Grammar Validation', () => {
  it('should not have Or conflicts', () => {
    const parser = new MyParser([])
    parser.validateGrammar()  // æœ‰é—®é¢˜ä¼šæŠ›å¼‚å¸¸
  })
})
```

**CI/CD**ï¼š
```typescript
// åœ¨æ„å»ºè„šæœ¬ä¸­æ£€æŸ¥
const parser = new MyParser([])
const result = parser.validateGrammar()
if (!result.success) {
  process.exit(1)  // é˜»æ­¢é”™è¯¯ä»£ç åˆå…¥
}
```

**é‡æ„æ—¶**ï¼š
```typescript
// ç¡®ä¿ä¿®æ”¹ä¸å¼•å…¥å†²çª
parser.validateGrammar({ verbose: true })
```

## ğŸ¯ æ ¸å¿ƒæ¦‚å¿µ

### 1. PEG é¡ºåºé€‰æ‹© vs ä¼ ç»Ÿæœ€é•¿åŒ¹é…

| ç‰¹æ€§ | Subhuti (PEG) | ä¼ ç»Ÿ LR/LALR |
|------|---------------|--------------|
| åŒ¹é…ç­–ç•¥ | **ç¬¬ä¸€ä¸ªæˆåŠŸ** | æœ€é•¿åŒ¹é… |
| è§„åˆ™é¡ºåº | â­â­â­ **å…³é”®** | ä¸é‡è¦ |
| å›æº¯ | âœ… æ”¯æŒ | âŒ ä¸æ”¯æŒ |
| äºŒä¹‰æ€§å¤„ç† | ç¨‹åºå‘˜æ§åˆ¶ | è‡ªåŠ¨æ£€æµ‹/æŠ¥é”™ |
| æ€§èƒ½ | å¿«ï¼ˆPackratç¼“å­˜ï¼‰ | ä¸­ç­‰ |

### 2. allowError æœºåˆ¶ï¼ˆæ™ºèƒ½é”™è¯¯ç®¡ç†ï¼‰

åœ¨ `Or` è§„åˆ™ä¸­ï¼š
- **å‰ N-1 åˆ†æ”¯**ï¼šå…è®¸å¤±è´¥ï¼Œå¤±è´¥æ—¶è¿”å› `undefined`ï¼ˆä¸æŠ›å¼‚å¸¸ï¼‰
- **æœ€ååˆ†æ”¯**ï¼šå¤±è´¥æ—¶æŠ›å‡ºè¯¦ç»†é”™è¯¯ï¼ˆç²¾ç¡®å®šä½é—®é¢˜ï¼‰

```typescript
Or([
  { alt: () => { /* åˆ†æ”¯1ï¼šå¤±è´¥ â†’ undefined */ } },
  { alt: () => { /* åˆ†æ”¯2ï¼šå¤±è´¥ â†’ undefined */ } },
  { alt: () => { /* åˆ†æ”¯3ï¼šå¤±è´¥ â†’ æŠ›å¼‚å¸¸ï¼ */ } }
])
```

### 3. Packrat Parsingï¼ˆè®°å¿†åŒ–è§£æï¼‰

Subhuti ä½¿ç”¨ **LRU ç¼“å­˜** é¿å…é‡å¤è§£æï¼š

```typescript
// åŒä¸€ä½ç½®çš„è§„åˆ™åªè§£æä¸€æ¬¡
Expression()  // é¦–æ¬¡è§£æï¼Œè€—æ—¶ 10ms
              // ç¼“å­˜ç»“æœï¼š{ success: true, endTokenIndex: 5, cst: ... }

Expression()  // å†æ¬¡è°ƒç”¨ï¼Œç›´æ¥è¿”å›ç¼“å­˜ï¼Œè€—æ—¶ < 1ms
```

**æ€§èƒ½æå‡**ï¼š
- å¤æ‚è¯­æ³•ï¼š5-10x åŠ é€Ÿ
- é€’å½’è§„åˆ™ï¼š100x+ åŠ é€Ÿï¼ˆé¿å…æŒ‡æ•°çº§æ—¶é—´å¤æ‚åº¦ï¼‰

## ğŸ“Š ä¸å…¶ä»–å·¥å…·å¯¹æ¯”

| å·¥å…· | Subhuti | ANTLR | PEG.js | Chevrotain |
|------|---------|-------|--------|------------|
| **è¯­è¨€** | TypeScript | Java/å¤šè¯­è¨€ | JavaScript | TypeScript |
| **é£æ ¼** | PEG | LL(*) | PEG | LL(k) |
| **å®šä¹‰æ–¹å¼** | è£…é¥°å™¨ | ç‹¬ç«‹è¯­æ³•æ–‡ä»¶ | ç‹¬ç«‹è¯­æ³•æ–‡ä»¶ | TypeScript API |
| **å›æº¯** | âœ… | âŒ | âœ… | âŒ |
| **æ€§èƒ½** | â­â­â­â­â­ | â­â­â­â­â­ | â­â­â­ | â­â­â­â­ |
| **æ˜“ç”¨æ€§** | â­â­â­â­â­ | â­â­â­ | â­â­â­â­ | â­â­â­â­ |
| **è°ƒè¯•** | å†…ç½® | å¤–éƒ¨å·¥å…· | ä¸­ç­‰ | è‰¯å¥½ |

## ğŸ“ æœ€ä½³å®è·µ

### âœ… æ¨è

1. **é•¿è§„åˆ™ä¼˜å…ˆ**ï¼šåœ¨ `Or` ä¸­å§‹ç»ˆæŠŠé•¿è§„åˆ™æ”¾åœ¨å‰é¢
2. **æ·»åŠ æ³¨é‡Š**ï¼šè¯´æ˜æ¯ä¸ª `Or` åˆ†æ”¯çš„ç”¨é€”å’Œé•¿åº¦
3. **ä½¿ç”¨ Option**ï¼šæ¯” `Or` æ›´æ¸…æ™°åœ°è¡¨è¾¾å¯é€‰éƒ¨åˆ†
4. **å¯ç”¨ç¼“å­˜**ï¼šç”Ÿäº§ç¯å¢ƒä¿æŒ `.cache(true)`
5. **æ‹†åˆ†å¤æ‚è§„åˆ™**ï¼šæé«˜å¯è¯»æ€§å’Œå¯ç»´æŠ¤æ€§

### âŒ é¿å…

1. **çŸ­è§„åˆ™åœ¨å‰**ï¼šä¼šå¯¼è‡´è§£æå¤±è´¥ï¼ˆæœ€å¸¸è§é”™è¯¯ï¼‰
2. **å¤æ‚çš„ Or åµŒå¥—**ï¼šéš¾ä»¥ç†è§£å’Œè°ƒè¯•
3. **è¿‡åº¦å›æº¯**ï¼šå½±å“æ€§èƒ½ï¼Œä¼˜åŒ–åˆ†æ”¯é¡ºåº

### ğŸ“ ä»£ç é£æ ¼å»ºè®®

```typescript
// âœ… æ¨èï¼šæ¸…æ™°çš„æ³¨é‡Šå’Œç»“æ„
PropertyDefinition() {
  this.Or([
    // é•¿è§„åˆ™ï¼š{ key: value }
    { alt: () => {
      this.PropertyName()
      this.Colon()
      this.AssignmentExpression()
    }},
    // ä¸­è§„åˆ™ï¼šæ–¹æ³•å®šä¹‰
    { alt: () => this.MethodDefinition() },
    // çŸ­è§„åˆ™ï¼š{ key } ç®€å†™
    { alt: () => this.IdentifierReference() }
  ])
}

// æˆ–è€…ä½¿ç”¨ Option ç®€åŒ–
PropertyDefinition() {
  this.PropertyName()
  this.Option(() => {
    this.Colon()
    this.AssignmentExpression()
  })
}
```

## ğŸ›¡ï¸ é—®é¢˜æ£€æµ‹ç³»ç»Ÿ

Subhuti å†…ç½®äº†å¼ºå¤§çš„é—®é¢˜æ£€æµ‹ç³»ç»Ÿï¼Œå¸®åŠ©ä½ åœ¨å¼€å‘é˜¶æ®µå¿«é€Ÿå‘ç°å’Œä¿®å¤å¸¸è§é”™è¯¯ã€‚

### è¿è¡Œæ—¶æ£€æµ‹

#### 1. å·¦é€’å½’æ£€æµ‹

è‡ªåŠ¨æ£€æµ‹å¹¶é˜»æ­¢å·¦é€’å½’è°ƒç”¨ï¼Œé¿å…æ ˆæº¢å‡ºï¼š

```typescript
@SubhutiRule
Expression() {
  this.Or([
    { alt: () => {
      this.Expression()  // âŒ å·¦é€’å½’ï¼
      this.consume('Plus')
      this.Number()
    }},
    { alt: () => this.Number() }
  ])
}

// è¿è¡Œæ—¶é”™è¯¯ï¼š
// âŒ æ£€æµ‹åˆ°å·¦é€’å½’
// è§„åˆ™ "Expression" åœ¨ token[0] å¤„é‡å¤è°ƒç”¨è‡ªå·±
// ğŸ’¡ Hint: æ£€æŸ¥è§„åˆ™å®šä¹‰ï¼Œç¡®ä¿åœ¨é€’å½’å‰æ¶ˆè´¹äº† token
```

#### 2. æ— é™å¾ªç¯æ£€æµ‹

æ£€æµ‹è§„åˆ™æˆåŠŸä½†ä¸æ¶ˆè´¹ token çš„æƒ…å†µï¼š

```typescript
@SubhutiRule
Statement() {
  // âŒ é”™è¯¯ï¼šæˆåŠŸä½†ä¸æ¶ˆè´¹ä»»ä½• token
  return this.curCst
}

// è¿è¡Œæ—¶é”™è¯¯ï¼š
// âŒ æ£€æµ‹åˆ°æ— é™å¾ªç¯
// è§„åˆ™æˆåŠŸæ—¶å¿…é¡»æ¶ˆè´¹è‡³å°‘ä¸€ä¸ª tokenï¼Œæˆ–ä½¿ç”¨ this.parserFail() æ ‡è®°å¤±è´¥
```

#### 3. ä¸æ­£ç¡®çš„å¤±è´¥æ ‡è®°

æ£€æµ‹è¿”å› `undefined` ä½†æœªè®¾ç½®å¤±è´¥çŠ¶æ€ï¼š

```typescript
@SubhutiRule
Identifier() {
  const cst = this.tokenConsumer.Identifier()
  if (cst && ReservedWords.has(cst.value!)) {
    // âŒ é”™è¯¯ï¼šåº”è¯¥ä½¿ç”¨ this.parserFail()
    return undefined
  }
  return cst
}

// æ­£ç¡®åšæ³•ï¼š
@SubhutiRule
Identifier() {
  const cst = this.tokenConsumer.Identifier()
  if (cst && ReservedWords.has(cst.value!)) {
    return this.parserFail()  // âœ… æ­£ç¡®æ ‡è®°å¤±è´¥
  }
  return cst
}
```

### é™æ€è¯­æ³•éªŒè¯

ä½¿ç”¨ `validateGrammar()` åœ¨å¼€å‘é˜¶æ®µæ£€æµ‹ Or è§„åˆ™å†²çªï¼š

```typescript
// åœ¨æµ‹è¯•ä¸­éªŒè¯è¯­æ³•
describe('Parser Grammar', () => {
  it('should not have Or conflicts', () => {
    const parser = new MyParser([])
    parser.validateGrammar()  // æœ‰é—®é¢˜ä¼šæŠ›å¼‚å¸¸
  })
})
```

**æ£€æµ‹çš„é—®é¢˜ç±»å‹ï¼š**

1. **å‰ç¼€å†²çª**ï¼šçŸ­è§„åˆ™åœ¨å‰ï¼Œé®è”½é•¿è§„åˆ™
2. **ç©ºè·¯å¾„å†²çª**ï¼šOption/Many åœ¨ç¬¬ä¸€ä¸ªåˆ†æ”¯å¯¼è‡´åç»­ä¸å¯è¾¾

### è°ƒè¯•æ¨¡å¼ç»Ÿè®¡ä¿¡æ¯

å¯ç”¨ `debug()` æ¨¡å¼å¯ä»¥æŸ¥çœ‹è¯¦ç»†çš„æ€§èƒ½å’Œè§£æç»Ÿè®¡ï¼š

```typescript
const parser = new MyParser(tokens).debug()
const cst = parser.Script()

// è‡ªåŠ¨è¾“å‡ºæ€§èƒ½æ‘˜è¦ã€ç¼“å­˜å‘½ä¸­ç‡ã€CST éªŒè¯ç­‰ä¿¡æ¯
```

**ç»Ÿè®¡ä¿¡æ¯è¯´æ˜ï¼š**
- **ç¼“å­˜å‘½ä¸­ç‡**ï¼šè¶Šé«˜è¶Šå¥½ï¼ˆé€šå¸¸ > 50%ï¼‰
- **Top æ…¢è§„åˆ™**ï¼šä¼˜åŒ–é‡ç‚¹
- **CST éªŒè¯**ï¼šç¡®ä¿è§£æå®Œæ•´æ€§

**æ³¨æ„**ï¼šç»Ÿè®¡ä¿¡æ¯ä»…ä¾›å‚è€ƒï¼Œä¸åš"å¥½å"åˆ¤æ–­ï¼Œç”±å¼€å‘è€…æ ¹æ®å®é™…åœºæ™¯åˆ†æã€‚

## ğŸ” è°ƒè¯•æŠ€å·§

### 1. å¯ç”¨è°ƒè¯•è¾“å‡º

```typescript
const parser = new MyParser(tokenStream).debug(true)
const cst = parser.Statement()
// è¾“å‡ºï¼š
// â†’ RuleEnter: Statement (tokenIndex: 0)
//   â†’ OrBranch: 1/3
//   â†’ RuleEnter: IfStatement (tokenIndex: 0)
//   âœ“ TokenConsume: IfTok "if"
//   ...
```

### 2. æ£€æŸ¥ CST ç»“æ„

```typescript
console.log(JSON.stringify(cst, null, 2))
```

### 3. æŸ¥çœ‹é”™è¯¯è¯¦æƒ…

```typescript
try {
  const cst = parser.Statement()
} catch (error) {
  console.error('è§£æå¤±è´¥:', error.message)
  console.error('ä½ç½®:', error.position)
  console.error('æœŸæœ›:', error.expected)
  console.error('å®é™…:', error.found)
  console.error('è§„åˆ™æ ˆ:', error.ruleStack)
}
```

## ğŸ¯ å®é™…åº”ç”¨

### Slime é¡¹ç›®
ä½¿ç”¨ Subhuti æ„å»ºå®Œæ•´çš„ **JavaScript ES2025** è§£æå™¨ï¼š
- âœ… æ”¯æŒæœ€æ–° ECMAScript 2025 è§„èŒƒçš„æ‰€æœ‰è¯­æ³•ç‰¹æ€§
- âœ… å®Œæ•´å®ç° import/exportã€async/awaitã€è£…é¥°å™¨ã€æ¨¡æ¿å­—ç¬¦ä¸²ç­‰
- âœ… CST â†’ AST è½¬æ¢
- âœ… ä»£ç ç”Ÿæˆå’Œ Source Map æ”¯æŒ

## ğŸ“š ç›¸å…³æ–‡æ¡£

- **[LOOKAHEAD_API.md](./LOOKAHEAD_API.md)** - Token å‰ç» API å®Œæ•´å‚è€ƒ
- **[DETECTION_IMPROVEMENT_SUMMARY.md](./DETECTION_IMPROVEMENT_SUMMARY.md)** - é—®é¢˜æ£€æµ‹ç³»ç»Ÿè¯¦ç»†è¯´æ˜
- **[RULE_PATH_IN_ERROR_SUMMARY.md](./RULE_PATH_IN_ERROR_SUMMARY.md)** - é”™è¯¯ä¿¡æ¯ä¸­çš„è§„åˆ™è·¯å¾„æ˜¾ç¤º

## ğŸ“„ License

MIT Â© [alamhubb](https://github.com/alamhubb)

## ğŸ¤ è´¡çŒ®

æ¬¢è¿æäº¤ Issue å’Œ Pull Requestï¼

---

**Subhuti** - è®©è¯­è¨€è½¬æ¢å¦‚ä¸ƒåäºŒå˜èˆ¬çµæ´» ğŸ­

