/**
 * Subhuti Parser - é«˜æ€§èƒ½ PEG Parser æ¡†æ¶
 *
 * æ ¸å¿ƒç‰¹æ€§ï¼š
 * - Packrat Parsingï¼ˆçº¿æ€§æ—¶é—´å¤æ‚åº¦ï¼ŒLRU ç¼“å­˜ï¼‰
 * - è¿”å›å€¼è¯­ä¹‰ï¼ˆæˆåŠŸè¿”å› CSTï¼Œå¤±è´¥è¿”å› undefinedï¼‰
 *
 * æ¶æ„è®¾è®¡ï¼š
 * - ç»§æ‰¿ SubhutiTokenLookaheadï¼ˆå‰ç»èƒ½åŠ›ï¼‰
 * - å®ç° ITokenConsumerContextï¼ˆæä¾›æ¶ˆè´¹æ¥å£ï¼‰
 * - æ”¯æŒæ³›å‹æ‰©å±• SubhutiTokenConsumer
 *
 * @version 5.0.0
 */

import SubhutiTokenLookahead from "./SubhutiTokenLookahead.ts"
import SubhutiCst from "./struct/SubhutiCst.ts";
import type SubhutiMatchToken from "./struct/SubhutiMatchToken.ts";
import {SubhutiErrorHandler, ParsingError} from "./SubhutiError.ts";
import {SubhutiTraceDebugger} from "./SubhutiDebug.ts";
import {SubhutiPackratCache, type SubhutiPackratCacheResult} from "./SubhutiPackratCache.ts";
import SubhutiTokenConsumer from "./SubhutiTokenConsumer.ts";
import {SubhutiDebugRuleTracePrint, setShowRulePath} from "./SubhutiDebugRuleTracePrint.ts";
import SubhutiLexer, {TokenCacheEntry} from "./SubhutiLexer.ts";
import {SubhutiCreateToken, DefaultMode, type LexerMode} from "./struct/SubhutiCreateToken.ts";
import {SubhutiGrammarValidator} from "./validation";


// ============================================
// ç±»å‹å®šä¹‰
// ============================================

export type RuleFunction = () => void

export interface SubhutiParserOr {
    alt: RuleFunction
}

export interface SubhutiBackData {
    /** æºç ä½ç½® */
    codeIndex: number
    /** è¡Œå· */
    codeLine: number
    /** åˆ—å· */
    codeColumn: number
    /** ä¸Šä¸€ä¸ª token åç§° */
    lastTokenName: string | null
    /** CST children é•¿åº¦ */
    curCstChildrenLength: number
    /** å·²è§£æ token æ•°é‡ï¼ˆç”¨äºæ¢å¤ parsedTokensï¼‰ */
    parsedTokensLength: number
}


export interface NextTokenInfo {
    codeIndex: number,
    rowNum: number,
    columnNumber: number
}

// ============================================
// è£…é¥°å™¨ç³»ç»Ÿï¼ˆå…¼å®¹æ—§ç‰ˆ experimentalDecorators å’Œ Stage 3ï¼‰
// ============================================

export function Subhuti<T extends new (...args: any[]) => SubhutiParser>(
    target: T,
    context?: ClassDecoratorContext
): T {
    return target
}

function wrapRuleMethod(originalMethod: Function, ruleName: string): Function {
    const wrappedFunction = function (this: SubhutiParser, ...args: any[]): SubhutiCst | undefined {
        return this.executeRuleWrapper(originalMethod, ruleName, this.constructor.name, ...args)
    }
    Object.defineProperty(wrappedFunction, 'name', {value: ruleName})
    Object.defineProperty(wrappedFunction, '__originalFunction__', {
        value: originalMethod, writable: false, enumerable: false, configurable: false
    })
    Object.defineProperty(wrappedFunction, '__isSubhutiRule__', {
        value: true, writable: false, enumerable: false, configurable: false
    })
    return wrappedFunction
}

export function SubhutiRule(
    targetOrMethod: any,
    propertyKeyOrContext: string | ClassMethodDecoratorContext,
    descriptor?: PropertyDescriptor
): any {
    const isLegacy = typeof propertyKeyOrContext === 'string'
    if (isLegacy) {
        descriptor!.value = wrapRuleMethod(descriptor!.value, propertyKeyOrContext as string)
        return descriptor
    } else {
        return wrapRuleMethod(targetOrMethod, targetOrMethod.name)
    }
}

export type SubhutiTokenConsumerConstructor<T extends SubhutiTokenConsumer<any>> =
    new (parser: SubhutiParser) => T

/**
 * Parser æ„é€ é€‰é¡¹
 */
export interface SubhutiParserOptions<T extends SubhutiTokenConsumer<any> = SubhutiTokenConsumer<any>> {
    /** TokenConsumer ç±»ï¼ˆå¯é€‰ï¼‰ */
    tokenConsumer?: SubhutiTokenConsumerConstructor<T>
    /** Token å®šä¹‰ï¼ˆç”¨äºæŒ‰éœ€è¯æ³•åˆ†ææ¨¡å¼ï¼‰ */
    tokenDefinitions?: SubhutiCreateToken[]
}

// ============================================
// SubhutiParser æ ¸å¿ƒç±»
// ============================================

export default class SubhutiParser<T extends SubhutiTokenConsumer<any> = SubhutiTokenConsumer<any>>
    extends SubhutiTokenLookahead {
    // æ ¸å¿ƒå­—æ®µ
    readonly tokenConsumer: T

    private readonly cstStack: SubhutiCst[] = []
    private readonly className: string

    // ============================================
    // æŒ‰éœ€è¯æ³•åˆ†æç›¸å…³å­—æ®µï¼ˆæ–°æ¶æ„ï¼‰
    // ============================================

    /** è¯æ³•åˆ†æå™¨ */
    protected _lexer: SubhutiLexer | null = null

    /** æºä»£ç  */
    protected _sourceCode: string = ''

    /** å½“å‰æºç ä½ç½®ï¼Œå¦‚æœç”¨tokenindexä¼šå¯¼è‡´tokenindexåŠ¨æ€å˜åŒ–ç¼“å­˜é—®é¢˜ï¼Œå› ä¸ºåŒæ ·çš„ä»£ç ä¸åŒçš„æ¨¡å¼è§£æå‡ºæ¥çš„tokensä¸ä¸€è‡´ */
    protected _codeIndex: number = 0

    /** å½“å‰è¡Œå· */
    protected _codeLine: number = 1

    /** å½“å‰åˆ—å· */
    protected _codeColumn: number = 1

    /** ä¸Šä¸€ä¸ª token åç§°ï¼ˆç”¨äºä¸Šä¸‹æ–‡çº¦æŸï¼‰- ä» parsedTokens åŠ¨æ€è·å– */
    protected get _lastTokenName(): string | null {
        const len = this._parsedTokens.length
        return len > 0 ? this._parsedTokens[len - 1].tokenName : null
    }

    protected _nextTokenInfo: NextTokenInfo | null = null

    /** Token ç¼“å­˜ï¼šä½ç½® â†’ æ¨¡å¼ â†’ ç¼“å­˜æ¡ç›® */
    protected _tokenCache: Map<number, Map<LexerMode, TokenCacheEntry>> = new Map()

    /** å·²è§£æçš„ token åˆ—è¡¨ï¼ˆç”¨äºè¾“å‡ºç»™ä½¿ç”¨è€…ï¼‰ */
    protected _parsedTokens: SubhutiMatchToken[] = []

    /**
     * åˆ†ææ¨¡å¼æ ‡å¿—
     * - true: åˆ†ææ¨¡å¼ï¼ˆç”¨äºè¯­æ³•éªŒè¯ï¼Œä¸æŠ›å¼‚å¸¸ï¼‰
     * - false: æ­£å¸¸æ¨¡å¼ï¼ˆç”¨äºè§£æï¼ŒæŠ›å¼‚å¸¸ï¼‰
     */
    private _analysisMode: boolean = false

    // è°ƒè¯•å’Œé”™è¯¯å¤„ç†
    private _debugger?: SubhutiTraceDebugger
    private readonly _errorHandler = new SubhutiErrorHandler()

    // æ— é™å¾ªç¯æ£€æµ‹ï¼ˆè°ƒç”¨æ ˆçŠ¶æ€æ£€æµ‹ï¼‰
    /**
     * å¾ªç¯æ£€æµ‹é›†åˆï¼šO(1) æ£€æµ‹ (rule, position) æ˜¯å¦é‡å¤
     * æ ¼å¼: "ruleName:position"
     */
    private readonly loopDetectionSet: Set<string> = new Set()

    // Packrat Parsingï¼ˆé»˜è®¤ LRU ç¼“å­˜ï¼‰
    enableMemoization: boolean = true
    private readonly _cache: SubhutiPackratCache

    getRuleStack() {
        return this.cstStack.map(item => item.name)
    }

    /**
     * æ„é€ å‡½æ•° - æŒ‰éœ€è¯æ³•åˆ†ææ¨¡å¼
     *
     * @param sourceCode æºä»£ç 
     * @param options é…ç½®é€‰é¡¹
     */
    constructor(
        sourceCode: string = '',
        options?: SubhutiParserOptions<T>,
    ) {
        super()
        this.className = this.constructor.name
        this._cache = new SubhutiPackratCache()

        // åˆå§‹åŒ–æºä»£ç å’Œä½ç½®
        this._sourceCode = sourceCode
        this._codeIndex = 0
        this._codeLine = 1
        this._codeColumn = 1
        this._tokenCache = new Map()
        this._parsedTokens = []

        // åˆå§‹åŒ–è¯æ³•åˆ†æå™¨
        if (options?.tokenDefinitions) {
            this._lexer = new SubhutiLexer(options.tokenDefinitions)
        }

        // åˆå§‹åŒ– TokenConsumer
        if (options?.tokenConsumer) {
            this.tokenConsumer = new options.tokenConsumer(this)
        } else {
            this.tokenConsumer = new SubhutiTokenConsumer(this) as T
        }
    }

    /**
     * è·å–å·²è§£æçš„ token åˆ—è¡¨
     */
    get parsedTokens(): SubhutiMatchToken[] {
        return this._parsedTokens
    }

    /**
     * è·å–æœ€åè§£æçš„ token ç´¢å¼•
     * @returns token ç´¢å¼•ï¼Œå¦‚æœæ²¡æœ‰å·²è§£æçš„ token åˆ™è¿”å› -1
     */
    get lastTokenIndex(): number {
        return this._parsedTokens.length - 1
    }

    /**
     * è·å–å½“å‰æ­£åœ¨å¤„ç†çš„ token ç´¢å¼•ï¼ˆä¸‹ä¸€ä¸ªå°†è¢« consume çš„ tokenï¼‰
     * @returns å½“å‰ token ç´¢å¼•
     */
    get currentTokenIndex(): number {
        return this._parsedTokens.length
    }

    // ============================================
    // æŒ‰éœ€è¯æ³•åˆ†æ
    // ============================================

    /**
     * è·å–æˆ–è§£ææŒ‡å®šä½ç½®å’Œæ¨¡å¼çš„ token
     *
     * @param codeIndex æºç ä½ç½®
     * @param line è¡Œå·
     * @param column åˆ—å·
     * @param mode è¯æ³•æ¨¡å¼ï¼ˆç”±æ’ä»¶æä¾›ï¼Œå¦‚ 'regexp', 'templateTail' ç­‰ï¼Œç©ºå­—ç¬¦ä¸²è¡¨ç¤ºé»˜è®¤æ¨¡å¼ï¼‰
     * @returns TokenCacheEntry æˆ– nullï¼ˆEOFï¼‰
     */
    protected _getOrParseToken(
        codeIndex: number,
        line: number,
        column: number,
        mode: LexerMode = DefaultMode
    ): TokenCacheEntry | null {
        if (!this._lexer) return null

        // 1. æŸ¥ç¼“å­˜
        const positionCache = this._tokenCache.get(codeIndex)
        if (positionCache?.has(mode)) {
            return positionCache.get(mode)!
        }

        // 2. è§£ææ–° token
        const entry = this._lexer.readTokenAt(
            this._sourceCode,
            codeIndex,
            line,
            column,
            mode,
            this._lastTokenName
        )

        if (!entry) return null  // EOF

        // 3. å­˜å…¥ç¼“å­˜
        if (!positionCache) {
            this._tokenCache.set(codeIndex, new Map())
        }
        this._tokenCache.get(codeIndex)!.set(mode, entry)

        return entry
    }

    /**
     * LA (LookAhead) - å‰ç»è·å– tokenï¼ˆæ”¯æŒæ¨¡å¼æ•°ç»„ï¼‰
     *
     * @param offset åç§»é‡ï¼ˆ1 = å½“å‰ tokenï¼Œ2 = ä¸‹ä¸€ä¸ª...ï¼‰
     * @param modes æ¯ä¸ªä½ç½®çš„è¯æ³•æ¨¡å¼ï¼ˆå¯é€‰ï¼Œä¸ä¼ ç”¨é»˜è®¤å€¼ï¼‰
     * @returns token æˆ– undefinedï¼ˆEOFï¼‰
     */
    protected override LA(offset: number = 1, modes?: LexerMode[]): SubhutiMatchToken | undefined {
        let currentIndex = this._codeIndex
        let currentLine = this._codeLine
        let currentColumn = this._codeColumn

        for (let i = 0; i < offset; i++) {
            // ç¡®å®šå½“å‰ token çš„è¯æ³•æ¨¡å¼
            const mode = modes?.[i] ?? DefaultMode

            // ä»ç¼“å­˜è·å–æˆ–è§£æ
            const entry = this._getOrParseToken(currentIndex, currentLine, currentColumn, mode)

            if (!entry) return undefined  // EOF

            // å¦‚æœæ˜¯æœ€åä¸€ä¸ªï¼Œè¿”å› token
            if (i === offset - 1) {
                return entry.token
            }

            // å¦åˆ™ï¼Œç§»åŠ¨åˆ°ä¸‹ä¸€ä¸ªä½ç½®
            currentIndex = entry.nextCodeIndex
            currentLine = entry.nextLine
            currentColumn = entry.nextColumn
        }

        return undefined
    }

    /**
     * peek - å‰ç»è·å– tokenï¼ˆæ”¯æŒæ¨¡å¼æ•°ç»„ï¼‰
     */
    protected override peek(offset: number = 1, modes?: LexerMode[]): SubhutiMatchToken | undefined {
        return this.LA(offset, modes)
    }

    /**
     * è·å–å½“å‰ tokenï¼ˆä½¿ç”¨é»˜è®¤è¯æ³•ç›®æ ‡ï¼‰
     */
    override get curToken(): SubhutiMatchToken | undefined {
        return this.LA(1)
    }

    // ============================================
    // å…¬å¼€ç»™ TokenConsumer ä½¿ç”¨çš„æ–¹æ³•
    // ============================================

    /**
     * ä¾› TokenConsumer ä½¿ç”¨çš„ consume æ–¹æ³•
     * @param tokenName token åç§°
     * @param mode è¯æ³•æ¨¡å¼ï¼ˆå¯é€‰ï¼‰
     */
    _consumeToken(tokenName: string, mode?: LexerMode): SubhutiCst | undefined {
        return this.consume(tokenName, mode)
    }

    /**
     * ä¾› TokenConsumer ä½¿ç”¨çš„æ ‡è®°è§£æå¤±è´¥æ–¹æ³•
     * ç”¨äºè½¯å…³é”®å­—æ£€æŸ¥å¤±è´¥æ—¶æ ‡è®°è§£æå¤±è´¥
     */
    _markParseFail(): void {
        this._parseSuccess = false
    }

    // ============================================
    // Parser å†…éƒ¨ Getter
    // ============================================

    get curCst(): SubhutiCst | undefined {
        return this.cstStack[this.cstStack.length - 1]
    }

    // åŠŸèƒ½å¼€å…³ï¼ˆé“¾å¼è°ƒç”¨ï¼‰
    cache(enable: boolean = true): this {
        this.enableMemoization = enable
        return this
    }

    /**
     * å¯ç”¨è°ƒè¯•æ¨¡å¼
     * @param showRulePath - æ˜¯å¦æ˜¾ç¤ºè§„åˆ™æ‰§è¡Œè·¯å¾„ï¼ˆé»˜è®¤ trueï¼‰
     *                       ä¼ å…¥ false æ—¶åªæ˜¾ç¤ºæ€§èƒ½ç»Ÿè®¡å’Œ CST éªŒè¯æŠ¥å‘Š
     */
    debug(showRulePath: boolean = true): this {
        setShowRulePath(showRulePath)
        this._debugger = new SubhutiTraceDebugger(this._parsedTokens)
        return this
    }

    errorHandler(enable: boolean = true): this {
        this._errorHandler.setDetailed(enable)
        return this
    }

    /**
     * å¯ç”¨åˆ†ææ¨¡å¼ï¼ˆç”¨äºè¯­æ³•éªŒè¯ï¼Œä¸æŠ›å¼‚å¸¸ï¼‰
     *
     * åœ¨åˆ†ææ¨¡å¼ä¸‹ï¼š
     * - ä¸æŠ›å‡ºå·¦é€’å½’å¼‚å¸¸
     * - ä¸æŠ›å‡ºæ— é™å¾ªç¯å¼‚å¸¸
     * - ä¸æŠ›å‡º Token æ¶ˆè´¹å¤±è´¥å¼‚å¸¸
     * - ä¸æŠ›å‡º EOF æ£€æµ‹å¼‚å¸¸
     *
     * @internal ä»…ä¾› SubhutiRuleCollector ä½¿ç”¨
     */
    enableAnalysisMode(): void {
        this._analysisMode = true
    }

    /**
     * ç¦ç”¨åˆ†ææ¨¡å¼ï¼ˆæ¢å¤æ­£å¸¸æ¨¡å¼ï¼‰
     *
     * @internal ä»…ä¾› SubhutiRuleCollector ä½¿ç”¨
     */
    disableAnalysisMode(): void {
        this._analysisMode = false
    }

    /**
     * å¯ç”¨è¯­æ³•éªŒè¯ï¼ˆé“¾å¼è°ƒç”¨ï¼‰ï¼ŒéªŒè¯è¯­æ³•ï¼ˆæ£€æµ‹ Or è§„åˆ™å†²çªï¼‰
     *
     * ç”¨æ³•ï¼š
     * ```typescript
     * const parser = new Es2025Parser(tokens).validate()
     * const cst = parser.Script()
     * ```
     *
     * @returns this - æ”¯æŒé“¾å¼è°ƒç”¨
     * @throws SubhutiGrammarValidationError - è¯­æ³•æœ‰å†²çªæ—¶æŠ›å‡º
     */
    validate(): this {
        SubhutiGrammarValidator.validate(this)
        return this
    }

    /**
     * æ£€æµ‹æ˜¯å¦æ˜¯ç›´æ¥æˆ–é—´æ¥å·¦é€’å½’
     *
     * âœ… è¿™ä¸ªæ–¹æ³•å¯ä»¥å‡†ç¡®åˆ¤æ–­å·¦é€’å½’
     * âŒ ä¸èƒ½åˆ¤æ–­æ˜¯å¦æ˜¯ Or åˆ†æ”¯é®è”½ï¼ˆè¿”å› false åªè¡¨ç¤ºä¸æ˜¯å·¦é€’å½’ï¼‰
     *
     * @param ruleName å½“å‰è§„åˆ™åç§°
     * @param ruleStack è§„åˆ™è°ƒç”¨æ ˆ
     * @returns true: ç¡®å®šæ˜¯å·¦é€’å½’, false: ä¸æ˜¯å·¦é€’å½’ï¼ˆä½†ä¸èƒ½ç¡®å®šæ˜¯ä»€ä¹ˆé—®é¢˜ï¼‰
     */
    private isDirectLeftRecursion(ruleName: string, ruleStack: string[]): boolean {
        // æ£€æŸ¥è§„åˆ™æ ˆä¸­æ˜¯å¦æœ‰ä»»ä½•è§„åˆ™å‡ºç°äº† >= 2 æ¬¡
        // è¿™å¯ä»¥æ£€æµ‹ç›´æ¥å·¦é€’å½’å’Œé—´æ¥å·¦é€’å½’

        const ruleCounts = new Map<string, number>()

        for (const rule of ruleStack) {
            ruleCounts.set(rule, (ruleCounts.get(rule) || 0) + 1)
        }

        // å¦‚æœä»»ä½•è§„åˆ™å‡ºç° >= 2 æ¬¡ï¼Œè¯´æ˜æœ‰é€’å½’
        for (const count of ruleCounts.values()) {
            if (count >= 2) {
                return true  // âœ… ç¡®å®šæ˜¯å·¦é€’å½’ï¼ˆç›´æ¥æˆ–é—´æ¥ï¼‰
            }
        }

        // å¦åˆ™ï¼Œä¸æ˜¯å·¦é€’å½’
        // ä½†å¯èƒ½æ˜¯å…¶ä»–é—®é¢˜ï¼šOr åˆ†æ”¯é®è”½ã€è§„åˆ™å®ç°é”™è¯¯ã€è¯­æ³•é”™è¯¯ç­‰
        return false  // âŒ ä¸æ˜¯å·¦é€’å½’ï¼ˆä½†ä¸ç¡®å®šå…·ä½“æ˜¯ä»€ä¹ˆé—®é¢˜ï¼‰
    }

    /**
     * æŠ›å‡ºå¾ªç¯é”™è¯¯ä¿¡æ¯
     *
     * @param ruleName å½“å‰è§„åˆ™åç§°
     */
    private throwLoopError(ruleName: string): never {
        // ğŸ” åˆ†ææ¨¡å¼ï¼šä¸æŠ›å¼‚å¸¸ï¼Œç›´æ¥è¿”å›
        if (this._analysisMode) {
            // æ ‡è®°è§£æå¤±è´¥ï¼Œè®© RuleCollector çŸ¥é“è¿™ä¸ªè§„åˆ™æœ‰é—®é¢˜
            this._parseSuccess = false
            return undefined as never
        }

        // è·å–å½“å‰ token ä¿¡æ¯
        const currentToken = this.curToken

        // ä» parsedTokens è·å–ä¸Šä¸‹æ–‡ï¼ˆæœ€è¿‘ 2 ä¸ª tokenï¼‰
        const tokenContext = this.getTokenContext(2)

        // è·å–ç¼“å­˜ç»Ÿè®¡
        const cacheStatsReport = this._cache.getStatsReport()

        // ğŸ” åˆ†æå¾ªç¯ç±»å‹ï¼šçœŸæ­£çš„å·¦é€’å½’ vs Or åˆ†æ”¯é®è”½
        const ruleStack = this.getRuleStack()
        const isDirectLeftRecursion = this.isDirectLeftRecursion(ruleName, ruleStack)
        const errorType = isDirectLeftRecursion ? 'left-recursion' : 'or-branch-shadowing'

        // åˆ›å»ºå¾ªç¯é”™è¯¯ï¼ˆå¹³é“ºç»“æ„ï¼‰
        throw this._errorHandler.createError({
            type: errorType,
            expected: '',
            found: currentToken,
            position: {
                tokenIndex: this.currentTokenIndex,
                codeIndex: this._codeIndex,
                line: currentToken?.rowNum || this._codeLine,
                column: currentToken?.columnStartNum || this._codeColumn
            },
            ruleStack: [...ruleStack],
            loopRuleName: ruleName,
            loopDetectionSet: Array.from(this.loopDetectionSet),
            loopCstDepth: this.cstStack.length,
            loopCacheStats: {
                hits: cacheStatsReport.hits,
                misses: cacheStatsReport.misses,
                hitRate: cacheStatsReport.hitRate,
                currentSize: cacheStatsReport.currentSize
            },
            loopTokenContext: tokenContext,
            hint: 'æ£€æŸ¥è§„åˆ™å®šä¹‰ï¼Œç¡®ä¿åœ¨é€’å½’å‰æ¶ˆè´¹äº† token'
        })
    }

    /**
     * è§„åˆ™æ‰§è¡Œå…¥å£ï¼ˆç”± @SubhutiRule è£…é¥°å™¨è°ƒç”¨ï¼‰
     * èŒè´£ï¼šå‰ç½®æ£€æŸ¥ â†’ å¾ªç¯æ£€æµ‹ â†’ Packrat ç¼“å­˜ â†’ æ ¸å¿ƒæ‰§è¡Œ â†’ åç½®å¤„ç†
     */
    executeRuleWrapper(targetFun: Function, ruleName: string, className: string, ...args: any[]): SubhutiCst | undefined {
        if (this.checkRuleIsThisClass(ruleName, className)) {
            return
        }
        const isTopLevel = this.cstStack.length === 0

        if (isTopLevel) {
            this.initTopLevelData()
        }

        if (this.parserFail) {
            return
        }

        const tokenIndex = this.currentTokenIndex
        const key = `${ruleName}:${tokenIndex}`

        // O(1) å¿«é€Ÿæ£€æµ‹æ˜¯å¦é‡å¤ï¼ˆå¾ªç¯æ£€æµ‹ï¼‰
        if (this.loopDetectionSet.has(key)) {
            this.throwLoopError(ruleName)
        }

        // å…¥æ ˆ
        this.loopDetectionSet.add(key)

        try {
            const startTime = this._debugger?.onRuleEnter(ruleName, tokenIndex)

            // Packrat Parsing ç¼“å­˜æŸ¥è¯¢
            if (this.enableMemoization) {
                const cached = this._cache.get(ruleName, tokenIndex)
                if (cached !== undefined) {
                    this._debugger?.onRuleExit(ruleName, true, startTime)

                    const cst = this.applyCachedResult(cached)
                    if (!cst.children?.length) {
                        cst.children = undefined
                    }
                    return cst
                }
            }

            // æ ¸å¿ƒæ‰§è¡Œ
            const startTokenIndex = tokenIndex

            const cst = this.executeRuleCore(ruleName, targetFun, ...args)

            // ç¼“å­˜å­˜å‚¨
            if (this.enableMemoization) {
                const endTokenIndex = this.currentTokenIndex

                // æå–æœ¬æ¬¡è§„åˆ™æ¶ˆè´¹çš„ token
                const consumedTokens = this._parseSuccess
                    ? this._parsedTokens.slice(startTokenIndex)
                    : undefined

                this._cache.set(ruleName, startTokenIndex, {
                    endTokenIndex: endTokenIndex,
                    cst: cst,
                    parseSuccess: this._parseSuccess,
                    parsedTokens: consumedTokens
                })
            }

            this.onRuleExitDebugHandler(ruleName, cst, isTopLevel, startTime)

            // é¡¶å±‚è§„åˆ™ï¼šæ£€æŸ¥æ˜¯å¦æ‰€æœ‰æºç éƒ½è¢«æ¶ˆè´¹
            if (isTopLevel && this._parseSuccess) {
                if (!this.isEof) {
                    const nextToken = this.LA(1)
                    throw new Error(
                        `Parser internal error: parsing succeeded but source code remains unconsumed. ` +
                        `Next token: "${nextToken?.tokenValue}" (${nextToken?.tokenName}) at position ${this._codeIndex}`
                    )
                }
            }

            // é¡¶å±‚è§„åˆ™å¤±è´¥æ—¶çš„é”™è¯¯å¤„ç†
            if (isTopLevel && this.parserFail) {
                this.handleTopLevelError(ruleName, startTokenIndex)
            }

            if (!cst.children?.length) {
                cst.children = undefined
            }
            return cst
        } finally {
            // å‡ºæ ˆï¼ˆæ— è®ºæˆåŠŸã€returnã€å¼‚å¸¸éƒ½ä¼šæ‰§è¡Œï¼‰
            this.loopDetectionSet.delete(key)
        }
    }

    private initTopLevelData() {
        // ã€é¡¶å±‚è§„åˆ™å¼€å§‹ã€‘é‡ç½®è§£æå™¨çŠ¶æ€
        this._parseSuccess = true
        this.cstStack.length = 0
        this.loopDetectionSet.clear()
        this._codeIndex = 0
        this._codeLine = 1
        this._codeColumn = 1
        this._parsedTokens = []
        this._tokenCache.clear()

        // é‡ç½®è°ƒè¯•å™¨çš„ç¼“å­˜å’Œç»Ÿè®¡
        this._debugger?.resetForNewParse?.(this._parsedTokens)
    }

    private checkRuleIsThisClass(ruleName: string, className: string): boolean {
        if (this.hasOwnProperty(ruleName)) {
            if (className !== this.className) {
                return true
            }
        }
        return false
    }

    private onRuleExitDebugHandler(
        ruleName: string,
        cst: SubhutiCst | undefined,
        isTopLevel: boolean,
        startTime?: number
    ): void {
        if (cst && !cst.children?.length) {
            cst.children = undefined
        }

        if (!isTopLevel) {
            this._debugger?.onRuleExit(ruleName, false, startTime)
        } else {
            // é¡¶å±‚è§„åˆ™å®Œæˆï¼Œè¾“å‡ºè°ƒè¯•ä¿¡æ¯
            if (this._debugger) {
                if ('setCst' in this._debugger) {
                    (this._debugger as any).setCst(cst)
                }
                (this._debugger as any)?.autoOutput?.()
            }
        }
    }

    /**
     * æ‰§è¡Œè§„åˆ™å‡½æ•°æ ¸å¿ƒé€»è¾‘
     * èŒè´£ï¼šåˆ›å»º CST â†’ æ‰§è¡Œè§„åˆ™ â†’ æˆåŠŸåˆ™æ·»åŠ åˆ°çˆ¶èŠ‚ç‚¹
     */
    private executeRuleCore(ruleName: string, targetFun: Function, ...args: any[]): SubhutiCst {
        const cst = new SubhutiCst()
        cst.name = ruleName
        cst.children = []

        this.cstStack.push(cst)

        // æ‰§è¡Œè§„åˆ™å‡½æ•°
        targetFun.apply(this, args)

        this.cstStack.pop()

        // æˆåŠŸæ—¶æ·»åŠ åˆ°çˆ¶èŠ‚ç‚¹å¹¶è®¾ç½®ä½ç½®
        if (this._parseSuccess) {
            const parentCst = this.cstStack[this.cstStack.length - 1]
            if (parentCst) {
                parentCst.children!.push(cst)
            }
            this.setLocation(cst)
        }

        return cst
    }

    private setLocation(cst: SubhutiCst): void {
        if (cst.children && cst.children[0]?.loc) {
            const lastChild = cst.children[cst.children.length - 1]
            cst.loc = {
                type: cst.name,
                start: cst.children[0].loc.start,
                // end: lastChild?.loc?.end || cst.children[0].loc.end
                end: lastChild?.loc?.end
            }
        }
    }

    /**
     * Or è§„åˆ™ - é¡ºåºé€‰æ‹©ï¼ˆPEG é£æ ¼ï¼‰
     *
     * æ ¸å¿ƒé€»è¾‘ï¼š
     * - ä¾æ¬¡å°è¯•æ¯ä¸ªåˆ†æ”¯ï¼Œç¬¬ä¸€ä¸ªæˆåŠŸçš„åˆ†æ”¯ç”Ÿæ•ˆ
     * - æ‰€æœ‰åˆ†æ”¯éƒ½å¤±è´¥åˆ™æ•´ä½“å¤±è´¥
     *
     * ä¼˜åŒ–ï¼šåªæœ‰æ¶ˆè´¹äº† token æ‰éœ€è¦å›æº¯ï¼ˆæ²¡æ¶ˆè´¹ = çŠ¶æ€æ²¡å˜ï¼‰
     */
    Or(alternatives: SubhutiParserOr[]): void {
        if (this.parserFail) {
            return
        }

        const savedState = this.saveState()
        const startCodeIndex = this._codeIndex
        const totalCount = alternatives.length
        const parentRuleName = this.curCst?.name || 'Unknown'

        // è¿›å…¥ Orï¼ˆæ•´ä¸ª Or è°ƒç”¨å¼€å§‹ï¼‰
        this._debugger?.onOrEnter?.(parentRuleName, startCodeIndex)

        for (let i = 0; i < totalCount; i++) {
            const alt = alternatives[i]
            const isLast = i === totalCount - 1

            // è¿›å…¥ Or åˆ†æ”¯
            this._debugger?.onOrBranch?.(i, totalCount, parentRuleName)

            alt.alt()

            // é€€å‡º Or åˆ†æ”¯ï¼ˆæ— è®ºæˆåŠŸè¿˜æ˜¯å¤±è´¥ï¼‰
            this._debugger?.onOrBranchExit?.(parentRuleName, i)

            if (this._parseSuccess) {
                // é€€å‡º Orï¼ˆæ•´ä¸ª Or è°ƒç”¨æˆåŠŸç»“æŸï¼‰
                this._debugger?.onOrExit?.(parentRuleName)
                return
            }

            // å‰ N-1 ä¸ªåˆ†æ”¯ï¼šå¤±è´¥åå›æº¯å¹¶é‡ç½®çŠ¶æ€ï¼Œç»§ç»­å°è¯•ä¸‹ä¸€ä¸ª
            if (!isLast) {
                this.restoreState(savedState)
                this._parseSuccess = true
            }
            // æœ€åä¸€ä¸ªåˆ†æ”¯ï¼šå¤±è´¥åä¸å›æº¯ï¼Œä¿æŒå¤±è´¥çŠ¶æ€
        }

        // é€€å‡º Orï¼ˆæ•´ä¸ª Or è°ƒç”¨å¤±è´¥ç»“æŸï¼‰
        this._debugger?.onOrExit?.(parentRuleName)
    }

    /**
     * Many è§„åˆ™ - 0æ¬¡æˆ–å¤šæ¬¡ï¼ˆEBNF { ... }ï¼‰
     *
     * å¾ªç¯æ‰§è¡Œç›´åˆ°å¤±è´¥æˆ–æ²¡æ¶ˆè´¹ token
     */
    Many(fn: RuleFunction): void {
        while (this.tryAndRestore(fn)) {
            // ç»§ç»­å¾ªç¯
        }
    }

    /**
     * Option è§„åˆ™ - 0æ¬¡æˆ–1æ¬¡ï¼ˆEBNF [ ... ]ï¼‰
     *
     * å°è¯•æ‰§è¡Œä¸€æ¬¡ï¼Œå¤±è´¥åˆ™å›æº¯ï¼Œä¸å½±å“æ•´ä½“è§£æçŠ¶æ€
     */
    Option(fn: RuleFunction): void {
        this.tryAndRestore(fn)
    }

    /**
     * AtLeastOne è§„åˆ™ - 1æ¬¡æˆ–å¤šæ¬¡
     *
     * ç¬¬ä¸€æ¬¡å¿…é¡»æˆåŠŸï¼Œåç»­å¾ªç¯æ‰§è¡Œç›´åˆ°å¤±è´¥
     */
    AtLeastOne(fn: RuleFunction): void {
        if (this.parserFail) {
            return
        }

        fn()

        while (this.tryAndRestore(fn)) {
            // ç»§ç»­å¾ªç¯
        }
    }

    /**
     * é¡¶å±‚è§„åˆ™å¤±è´¥æ—¶çš„é”™è¯¯å¤„ç†
     *
     * @param ruleName è§„åˆ™å
     * @param startIndex è§„åˆ™å¼€å§‹æ—¶çš„æºç ä½ç½®
     */
    private handleTopLevelError(ruleName: string, startIndex: number): void {
        // åˆ†ææ¨¡å¼ï¼šä¸æŠ›é”™ï¼Œç”¨äºè¯­æ³•éªŒè¯
        if (this._analysisMode) {
            return
        }

        // æ­£å¸¸æ¨¡å¼ï¼šæŠ›å‡ºè§£æé”™è¯¯
        const noTokenConsumed = this.currentTokenIndex === startIndex
        const found = this.curToken

        throw this._errorHandler.createError({
            type: 'parsing',
            expected: noTokenConsumed ? 'valid syntax' : 'EOF (end of file)',
            found: found,
            position: {
                tokenIndex: this.currentTokenIndex,
                codeIndex: this._codeIndex,
                line: found?.rowNum ?? this._codeLine,
                column: found?.columnStartNum ?? this._codeColumn
            },
            ruleStack: this.getRuleStack().length > 0 ? this.getRuleStack() : [ruleName]
        })
    }

    get parserFailOrIsEof() {
        return this.parserFail || this.isEof
    }

    /**
     * æ¶ˆè´¹ tokenï¼ˆæ™ºèƒ½é”™è¯¯ç®¡ç†ï¼‰
     * - å¤±è´¥æ—¶è¿”å› undefinedï¼Œä¸æŠ›å¼‚å¸¸
     * - protected: å¿…é¡»é€šè¿‡ tokenConsumer çš„å°è£…æ–¹æ³•æ¶ˆè´¹ token
     * @param tokenName token åç§°
     * @param mode è¯æ³•æ¨¡å¼ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä½¿ç”¨ _currentModeï¼‰
     */
    protected consume(tokenName: string, mode?: LexerMode): SubhutiCst | undefined {
        if (this.parserFail) {
            return
        }

        if (this.isEof) {
            this._parseSuccess = false
            return
        }

        // è·å–å½“å‰ tokenï¼ˆä½¿ç”¨ä¼ å…¥çš„ mode æˆ–é»˜è®¤ modeï¼‰
        const effectiveMode = mode ?? DefaultMode
        const entry = this._getOrParseToken(
            this._codeIndex,
            this._codeLine,
            this._codeColumn,
            effectiveMode
        )

        if (!entry) {
            this._parseSuccess = false
            return
        }

        const token = entry.token

        if (token.tokenName !== tokenName) {
            this._parseSuccess = false

            this._debugger?.onTokenConsume(
                this._codeIndex,
                token.tokenValue,
                token.tokenName,
                tokenName,
                false
            )

            return
        }

        this._debugger?.onTokenConsume(
            this._codeIndex,
            token.tokenValue,
            token.tokenName,
            tokenName,
            true
        )

        const cst = this.generateCstByToken(token)

        // æ›´æ–°ä½ç½®
        this._codeIndex = entry.nextCodeIndex
        this._codeLine = entry.nextLine
        this._codeColumn = entry.nextColumn

        // æ·»åŠ åˆ°å·²è§£æåˆ—è¡¨ï¼ˆ_lastTokenName ä¼šè‡ªåŠ¨ä» parsedTokens è·å–ï¼‰
        this._parsedTokens.push(token)

        return cst
    }

    private generateCstByToken(token: SubhutiMatchToken): SubhutiCst {
        const cst = new SubhutiCst()
        cst.name = token.tokenName
        cst.value = token.tokenValue
        cst.loc = {
            type: token.tokenName,
            value: token.tokenValue,
            start: {
                index: token.index || 0,
                line: token.rowNum || 0,
                column: token.columnStartNum || 0
            },
            end: {
                index: (token.index || 0) + token.tokenValue.length,
                line: token.rowNum || 0,
                column: token.columnEndNum || 0
            }
        }

        // æ·»åŠ åˆ°å½“å‰ CST
        const currentCst = this.curCst
        if (currentCst) {
            currentCst.children!.push(cst)
        }

        return cst
    }

    // å›æº¯æœºåˆ¶
    private saveState(): SubhutiBackData {
        const currentCst = this.curCst
        return {
            codeIndex: this._codeIndex,
            codeLine: this._codeLine,
            codeColumn: this._codeColumn,
            lastTokenName: this._lastTokenName,
            curCstChildrenLength: currentCst?.children?.length || 0,
            parsedTokensLength: this._parsedTokens.length
        }
    }

    private restoreState(backData: SubhutiBackData): void {
        const fromIndex = this._codeIndex
        const toIndex = backData.codeIndex

        if (fromIndex !== toIndex) {
            this._debugger?.onBacktrack?.(fromIndex, toIndex)
        }

        this._codeIndex = backData.codeIndex
        this._codeLine = backData.codeLine
        this._codeColumn = backData.codeColumn

        // æ¢å¤ parsedTokensï¼ˆ_lastTokenName ä¼šè‡ªåŠ¨ä» parsedTokens è·å–ï¼‰
        this._parsedTokens.length = backData.parsedTokensLength

        const currentCst = this.curCst
        if (currentCst) {
            currentCst.children!.length = backData.curCstChildrenLength
        }
    }

    /**
     * æ£€æŸ¥æ˜¯å¦å·²åˆ°è¾¾æºç æœ«å°¾
     */
    get isEof(): boolean {
        // å…ˆæ£€æŸ¥æ˜¯å¦å·²ç»åˆ°è¾¾ä»£ç æœ«å°¾
        if (this._codeIndex >= this._sourceCode.length) {
            return true
        }

        // å°è¯•è·å–ä¸‹ä¸€ä¸ª tokenï¼ˆä¼šè·³è¿‡ç©ºç™½ï¼‰
        try {
            const entry = this._getOrParseToken(
                this._codeIndex,
                this._codeLine,
                this._codeColumn,
                DefaultMode
            )
            return entry === null
        } catch {
            // å¦‚æœè¯æ³•åˆ†æå™¨æ— æ³•è¯†åˆ«å­—ç¬¦ï¼Œè¯´æ˜ä¸æ˜¯ EOF
            // è®©åç»­çš„æ¶ˆè´¹æ“ä½œå¤„ç†è¿™ä¸ªé”™è¯¯
            return false
        }
    }

    /**
     * å°è¯•æ‰§è¡Œå‡½æ•°ï¼Œå¤±è´¥æ—¶è‡ªåŠ¨å›æº¯å¹¶é‡ç½®çŠ¶æ€
     *
     * @param fn è¦æ‰§è¡Œçš„å‡½æ•°
     * @returns true: æˆåŠŸä¸”æ¶ˆè´¹äº† tokenï¼Œfalse: å¤±è´¥æˆ–æ²¡æ¶ˆè´¹ token
     */
    private tryAndRestore(fn: () => void): boolean {
        if (this.parserFailOrIsEof) {
            return false
        }
        const savedState = this.saveState()
        const startIndex = this._codeIndex

        fn()

        if (this.parserFail) {
            // è®°å½•éƒ¨åˆ†åŒ¹é…å¹¶å›æº¯
            this.restoreState(savedState)
            this._parseSuccess = true
            return false
        }

        // æˆåŠŸä½†æ²¡æ¶ˆè´¹ token â†’ è¿”å› falseï¼ˆé˜²æ­¢æ— é™å¾ªç¯ï¼‰
        return this._codeIndex !== startIndex
    }

    /**
     * åº”ç”¨ç¼“å­˜ç»“æœï¼ˆæ¢å¤çŠ¶æ€ï¼‰
     */
    private applyCachedResult(cached: SubhutiPackratCacheResult): SubhutiCst {
        // æ¢å¤æ¶ˆè´¹çš„ token
        if (cached.parsedTokens && cached.parsedTokens.length > 0) {
            this._parsedTokens.push(...cached.parsedTokens)

            // ä»æœ€åä¸€ä¸ª token æ¢å¤è¯æ³•åˆ†æä½ç½®
            const lastToken = cached.parsedTokens[cached.parsedTokens.length - 1]
            this._codeIndex = lastToken.index + lastToken.tokenValue.length
            this._codeLine = lastToken.rowNum
            this._codeColumn = lastToken.columnEndNum
            // _lastTokenName ä¼šè‡ªåŠ¨ä» parsedTokens è·å–
        }

        this._parseSuccess = cached.parseSuccess

        // æˆåŠŸæ—¶æ·»åŠ åˆ°çˆ¶èŠ‚ç‚¹
        if (cached.parseSuccess) {
            const parentCst = this.cstStack[this.cstStack.length - 1]
            if (parentCst) {
                parentCst.children!.push(cached.cst)
            }
        }

        return cached.cst
    }

    // ============================================
    // Error Helper Methods
    // ============================================

    /**
     * è·å– token ä¸Šä¸‹æ–‡ï¼ˆä» parsedTokens è·å–æœ€è¿‘çš„ N ä¸ª tokenï¼‰
     *
     * @param contextSize - ä¸Šä¸‹æ–‡å¤§å°ï¼ˆé»˜è®¤ 2ï¼‰
     * @returns token ä¸Šä¸‹æ–‡æ•°ç»„
     */
    private getTokenContext(contextSize: number = 2): SubhutiMatchToken[] {
        const tokens = this._parsedTokens
        const len = tokens.length
        const start = Math.max(0, len - contextSize)
        return tokens.slice(start)
    }

    /**
     * ç”Ÿæˆå½“å‰è§„åˆ™è·¯å¾„çš„å­—ç¬¦ä¸²ï¼ˆç”¨äºé”™è¯¯ä¿¡æ¯ï¼‰
     *
     * @returns æ ¼å¼åŒ–åçš„è§„åˆ™è·¯å¾„å­—ç¬¦ä¸²æ•°ç»„
     */
    private formatCurrentRulePath(): string[] {
        if (!this._debugger) {
            // å¦‚æœæ²¡æœ‰è°ƒè¯•å™¨ï¼Œä½¿ç”¨ç®€å•æ ¼å¼
            return this.formatSimpleRulePath()
        }

        // ä½¿ç”¨è°ƒè¯•å™¨çš„æ ¼å¼åŒ–æ–¹æ³•
        const ruleStack = this._debugger.ruleStack
        if (!ruleStack || ruleStack.length === 0) {
            return ['  (empty)']
        }

        return SubhutiDebugRuleTracePrint.formatPendingOutputs_NonCache_Impl(ruleStack)
    }

    /**
     * ç®€å•æ ¼å¼åŒ–è§„åˆ™è·¯å¾„ï¼ˆå½“æ²¡æœ‰è°ƒè¯•å™¨æ—¶ï¼‰
     */
    private formatSimpleRulePath(): string[] {
        const ruleStack = this.getRuleStack()
        if (ruleStack.length === 0) {
            return ['  (empty)']
        }

        const lines: string[] = []
        for (let i = 0; i < ruleStack.length; i++) {
            const rule = ruleStack[i]
            const isLast = i === ruleStack.length - 1
            const indent = '  '.repeat(i)
            const connector = i === 0 ? '' : 'â””â”€ '
            const marker = isLast ? ' â† å½“å‰ä½ç½®' : ''

            lines.push(`  ${indent}${connector}${rule}${marker}`)
        }

        return lines
    }

    /**
     * åˆ›å»ºæ— é™å¾ªç¯é”™è¯¯
     *
     * @param ruleName - è§„åˆ™åç§°
     * @param hint - ä¿®å¤æç¤º
     * @returns ParsingError å®ä¾‹ï¼ˆåˆ†ææ¨¡å¼ä¸‹è¿”å› nullï¼‰
     */
    private createInfiniteLoopError(ruleName: string, hint: string): ParsingError {
        // ğŸ” åˆ†ææ¨¡å¼ï¼šä¸åˆ›å»ºé”™è¯¯ï¼Œæ ‡è®°å¤±è´¥å¹¶è¿”å› null
        if (this._analysisMode) {
            this._parseSuccess = false
            return null as any  // åˆ†ææ¨¡å¼ä¸‹ä¸ä¼šçœŸæ­£ä½¿ç”¨è¿™ä¸ªè¿”å›å€¼
        }

        // ç”Ÿæˆè§„åˆ™è·¯å¾„
        const rulePathLines = this.formatCurrentRulePath()
        const rulePath = rulePathLines.join('\n')

        // ğŸ” æ£€æµ‹æ˜¯å¦æ˜¯å·¦é€’å½’ï¼ˆå‡†ç¡®åˆ¤æ–­ï¼‰
        const ruleStack = this.getRuleStack()
        const isLeftRecursion = this.isDirectLeftRecursion(ruleName, ruleStack)

        // âœ… åªæœ‰ç¡®å®šæ˜¯å·¦é€’å½’æ—¶æ‰ä½¿ç”¨ 'left-recursion' ç±»å‹
        // âŒ ä¸ç¡®å®šçš„æƒ…å†µä½¿ç”¨ 'infinite-loop'ï¼Œä¸æ–­è¨€æ˜¯ Or é®è”½
        const errorType = isLeftRecursion ? 'left-recursion' : 'infinite-loop'

        return this._errorHandler.createError({
            type: errorType,
            expected: '',
            found: this.curToken,
            position: {
                tokenIndex: this.currentTokenIndex,
                codeIndex: this._codeIndex,
                line: this.curToken?.rowNum || this._codeLine,
                column: this.curToken?.columnStartNum || this._codeColumn
            },
            ruleStack: [...ruleStack],
            loopRuleName: ruleName,
            loopDetectionSet: [],
            loopCstDepth: this.cstStack.length,
            loopTokenContext: this.getTokenContext(2),
            hint: hint,
            rulePath: rulePath
        })
    }
}

